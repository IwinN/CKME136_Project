{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automated detection of IDC in breast cancer whole slide image patches using Convoluted Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-20T03:23:45.956865Z",
     "start_time": "2020-07-20T03:23:45.953904Z"
    }
   },
   "source": [
    "#  Introduction "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Over the past couple of years, there has been a rise in using deep learning for medical image analysis with increasing success. Deep learning in the field of healthcare is used to identify patterns, classify and segment medical images. As with most image related tasks, convolutional neural networks are used to do this.\n",
    "The classification problem tackled here is to classify histopathology slides of Invasive Ductal Carcinoma (IDC) as either malignant or benign.\n",
    "\n",
    "<img src= \"https://miro.medium.com/max/770/1*dD7oWfCLnS8kHPZLqHo5yg.png\">\n",
    "<i>Histopathology slide of a malignant tumour. \n",
    "Image credits: Department of Pathology at Johns Hopkins University</i>\n",
    "\n",
    "IDC is a type of breast cancer, where the cancer has spread to the surrounding breast tissue.\n",
    "\n",
    "Cancer tumours can be classified into two types: malignant and benign. A benign tumor is one which does not invade its surrounding tissues whereas a malignant tumor is one which may spread to its surrounding tissues or other parts of the body."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding the dataset\n",
    "The dataset I will use can be downloaded __[here]( http://andrewjanowczyk.com/wp-static/IDC_regular_ps50_idx5.zip)__\n",
    "\n",
    "The dataset consists of 162 whole mount slide images of breast cancer specimens scanned at 40x. From that, 277,524 patches of size 50 x 50 were extracted, out of which 198,738 are IDC negative (benign) and 78,786 are IDC positive (malignant).\n",
    "\n",
    "Each patch’s file name is of the format:\n",
    "\n",
    "u_xX_yY_classC.png → example 10253_idx5_x1351_y1101_class0.png\n",
    "\n",
    "Where \n",
    "- u is the patient ID (10253_idx5), \n",
    "- X is the x-coordinate of where this patch was cropped from, \n",
    "- Y is the y-coordinate of where this patch was cropped from, and\n",
    "- C indicates the class where <b> 0 is non-IDC (benign)</b> and <b> 1 is IDC (malignant)</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-27T08:25:23.896245Z",
     "start_time": "2020-07-27T08:25:20.964942Z"
    }
   },
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import fnmatch\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-27T08:25:33.264670Z",
     "start_time": "2020-07-27T08:25:24.621986Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\iwin\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\iwin\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\iwin\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\iwin\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\iwin\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\iwin\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\iwin\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\iwin\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\iwin\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\iwin\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\iwin\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\iwin\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "sess = tf.Session() # to check which GPU tensorflow is using "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-27T08:25:37.290624Z",
     "start_time": "2020-07-27T08:25:36.950622Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the Dataset\n",
    "I will create two variable class_Zero and class_One and save the image locations of all class 0 and class 1 images in these variables respectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-27T08:26:00.654793Z",
     "start_time": "2020-07-27T08:25:41.067760Z"
    }
   },
   "outputs": [],
   "source": [
    "image_Patches = glob('D:\\DataAnalysisRyerson\\CKME136_Capstone\\Resources\\Breast cancer\\**\\*.png', recursive=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-27T08:27:03.049317Z",
     "start_time": "2020-07-27T08:27:02.065646Z"
    }
   },
   "outputs": [],
   "source": [
    "pattern_Zero = '*class0.png'\n",
    "pattern_One = '*class1.png'\n",
    "\n",
    "#to save the file location of all images with file name class0\n",
    "class_Zero = fnmatch.filter(image_Patches, pattern_Zero)\n",
    "\n",
    "#to save the file location of all images with file name class1\n",
    "class_One = fnmatch.filter(image_Patches, pattern_One) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I create a function process_images that takes the starting and end index of the images. The function reads the image using OpenCV's cv2.imread() and resizes the images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-27T08:27:05.522164Z",
     "start_time": "2020-07-27T08:27:05.495228Z"
    }
   },
   "outputs": [],
   "source": [
    "def process_images(lowerIndex,upperIndex):\n",
    "    \"\"\"\n",
    "    Returns two arrays: \n",
    "        x is an array of resized images\n",
    "        y is an array of corresponding labels\n",
    "    \"\"\" \n",
    "#Resizing all the images to a standard format of dimensions 50X50X3    \n",
    "    height = 50\n",
    "    width = 50\n",
    "    channels = 3\n",
    "    \n",
    "    x = [] # a list to store image data\n",
    "    y = [] # a list to store corresponding class\n",
    "    for img in image_Patches[lowerIndex:upperIndex]:\n",
    "        full_size_image = cv2.imread(img)\n",
    "        image = (cv2.resize(full_size_image, (width,height), interpolation=cv2.INTER_CUBIC))\n",
    "        x.append(image)\n",
    "        if img in class_Zero:\n",
    "            y.append(0)\n",
    "        elif img in class_One:\n",
    "            y.append(1)\n",
    "        else:\n",
    "            return\n",
    "    return x,y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will analyze the images from index 0 to 60000 in the beginning and keep tuning this hyperparameter to improve the accuracy of the model. This image data or pixel value is stored in the list X and its corresponding class is stored in list Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-27T08:33:33.521067Z",
     "start_time": "2020-07-27T08:27:11.355300Z"
    }
   },
   "outputs": [],
   "source": [
    "X, Y = process_images(0,100000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "To save space, the list X is first converted to a numpy array and then casted to type float32 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-27T08:34:29.043142Z",
     "start_time": "2020-07-27T08:34:28.547851Z"
    }
   },
   "outputs": [],
   "source": [
    "X = np.array(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-27T07:52:36.650444Z",
     "start_time": "2020-07-27T07:52:36.643457Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[206, 164, 226],\n",
       "         [196, 154, 224],\n",
       "         [211, 175, 225],\n",
       "         ...,\n",
       "         [237, 221, 240],\n",
       "         [214, 184, 232],\n",
       "         [235, 213, 243]],\n",
       "\n",
       "        [[188, 142, 217],\n",
       "         [179, 130, 221],\n",
       "         [196, 150, 224],\n",
       "         ...,\n",
       "         [204, 170, 227],\n",
       "         [215, 180, 229],\n",
       "         [232, 212, 236]],\n",
       "\n",
       "        [[212, 178, 237],\n",
       "         [199, 157, 229],\n",
       "         [175, 125, 218],\n",
       "         ...,\n",
       "         [217, 184, 221],\n",
       "         [193, 153, 190],\n",
       "         [208, 164, 227]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[192, 145, 217],\n",
       "         [184, 129, 214],\n",
       "         [183, 129, 212],\n",
       "         ...,\n",
       "         [185, 122, 194],\n",
       "         [193, 143, 204],\n",
       "         [188, 129, 189]],\n",
       "\n",
       "        [[192, 144, 218],\n",
       "         [185, 128, 213],\n",
       "         [171, 121, 208],\n",
       "         ...,\n",
       "         [145,  79, 136],\n",
       "         [174, 111, 184],\n",
       "         [176, 112, 188]],\n",
       "\n",
       "        [[181, 125, 212],\n",
       "         [181, 136, 211],\n",
       "         [206, 162, 220],\n",
       "         ...,\n",
       "         [152,  90, 127],\n",
       "         [202, 167, 213],\n",
       "         [211, 180, 215]]],\n",
       "\n",
       "\n",
       "       [[[197, 150, 219],\n",
       "         [201, 158, 217],\n",
       "         [205, 173, 228],\n",
       "         ...,\n",
       "         [199, 165, 198],\n",
       "         [224, 204, 230],\n",
       "         [221, 193, 231]],\n",
       "\n",
       "        [[195, 150, 223],\n",
       "         [192, 140, 222],\n",
       "         [186, 133, 213],\n",
       "         ...,\n",
       "         [193, 143, 218],\n",
       "         [197, 148, 218],\n",
       "         [185, 131, 215]],\n",
       "\n",
       "        [[176, 125, 203],\n",
       "         [192, 143, 218],\n",
       "         [199, 163, 227],\n",
       "         ...,\n",
       "         [188, 137, 210],\n",
       "         [177, 121, 203],\n",
       "         [183, 124, 192]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[242, 234, 247],\n",
       "         [248, 249, 247],\n",
       "         [247, 247, 248],\n",
       "         ...,\n",
       "         [242, 240, 245],\n",
       "         [247, 244, 249],\n",
       "         [239, 234, 243]],\n",
       "\n",
       "        [[246, 243, 249],\n",
       "         [247, 240, 243],\n",
       "         [246, 241, 248],\n",
       "         ...,\n",
       "         [251, 247, 247],\n",
       "         [246, 244, 247],\n",
       "         [251, 246, 249]],\n",
       "\n",
       "        [[226, 204, 230],\n",
       "         [244, 247, 246],\n",
       "         [249, 245, 250],\n",
       "         ...,\n",
       "         [250, 243, 249],\n",
       "         [248, 248, 251],\n",
       "         [247, 247, 248]]],\n",
       "\n",
       "\n",
       "       [[[249, 245, 248],\n",
       "         [248, 246, 248],\n",
       "         [253, 246, 249],\n",
       "         ...,\n",
       "         [248, 249, 249],\n",
       "         [249, 246, 247],\n",
       "         [248, 244, 248]],\n",
       "\n",
       "        [[246, 246, 248],\n",
       "         [247, 245, 248],\n",
       "         [248, 248, 250],\n",
       "         ...,\n",
       "         [246, 243, 249],\n",
       "         [247, 244, 252],\n",
       "         [247, 250, 249]],\n",
       "\n",
       "        [[238, 231, 241],\n",
       "         [240, 225, 239],\n",
       "         [242, 237, 243],\n",
       "         ...,\n",
       "         [251, 244, 248],\n",
       "         [249, 248, 245],\n",
       "         [251, 242, 249]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[249, 247, 248],\n",
       "         [249, 247, 248],\n",
       "         [249, 247, 248],\n",
       "         ...,\n",
       "         [245, 242, 245],\n",
       "         [238, 227, 241],\n",
       "         [203, 159, 216]],\n",
       "\n",
       "        [[249, 247, 248],\n",
       "         [249, 247, 248],\n",
       "         [249, 247, 249],\n",
       "         ...,\n",
       "         [249, 242, 249],\n",
       "         [222, 193, 229],\n",
       "         [171, 111, 161]],\n",
       "\n",
       "        [[249, 247, 249],\n",
       "         [249, 247, 249],\n",
       "         [249, 247, 249],\n",
       "         ...,\n",
       "         [247, 248, 247],\n",
       "         [230, 210, 235],\n",
       "         [177, 120, 186]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[ 93,  47,  96],\n",
       "         [104,  56, 118],\n",
       "         [116,  64, 120],\n",
       "         ...,\n",
       "         [110,  63, 130],\n",
       "         [115,  80, 172],\n",
       "         [120,  85, 168]],\n",
       "\n",
       "        [[106,  53, 103],\n",
       "         [ 83,  30,  72],\n",
       "         [102,  53,  94],\n",
       "         ...,\n",
       "         [116,  79, 187],\n",
       "         [139, 102, 186],\n",
       "         [148, 109, 170]],\n",
       "\n",
       "        [[112,  59, 108],\n",
       "         [103,  54, 109],\n",
       "         [124,  82, 129],\n",
       "         ...,\n",
       "         [127,  85, 171],\n",
       "         [132,  92, 175],\n",
       "         [ 97,  59, 123]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[133,  88, 163],\n",
       "         [120,  76, 155],\n",
       "         [111,  67, 155],\n",
       "         ...,\n",
       "         [170, 145, 195],\n",
       "         [130,  87, 126],\n",
       "         [120,  80, 156]],\n",
       "\n",
       "        [[ 98,  49,  98],\n",
       "         [103,  57, 107],\n",
       "         [129,  79, 138],\n",
       "         ...,\n",
       "         [149, 112, 175],\n",
       "         [118,  79, 182],\n",
       "         [111,  67, 149]],\n",
       "\n",
       "        [[ 86,  46,  97],\n",
       "         [ 82,  33,  73],\n",
       "         [ 76,  32,  72],\n",
       "         ...,\n",
       "         [160, 123, 172],\n",
       "         [103,  62, 148],\n",
       "         [105,  69, 169]]],\n",
       "\n",
       "\n",
       "       [[[110,  65, 148],\n",
       "         [111,  70, 144],\n",
       "         [107,  63, 139],\n",
       "         ...,\n",
       "         [117,  72, 154],\n",
       "         [103,  68, 162],\n",
       "         [110,  72, 159]],\n",
       "\n",
       "        [[106,  63, 136],\n",
       "         [109,  65, 154],\n",
       "         [122,  80, 163],\n",
       "         ...,\n",
       "         [122,  82, 161],\n",
       "         [126,  84, 158],\n",
       "         [125,  82, 156]],\n",
       "\n",
       "        [[149, 111, 175],\n",
       "         [143, 100, 160],\n",
       "         [123,  84, 131],\n",
       "         ...,\n",
       "         [112,  67, 138],\n",
       "         [116,  71, 143],\n",
       "         [117,  76, 161]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 69,  27,  58],\n",
       "         [ 60,  21,  55],\n",
       "         [ 44,  10,  32],\n",
       "         ...,\n",
       "         [104,  53, 106],\n",
       "         [126,  84, 146],\n",
       "         [132,  94, 179]],\n",
       "\n",
       "        [[ 67,  27,  57],\n",
       "         [159, 135, 165],\n",
       "         [ 79,  47,  77],\n",
       "         ...,\n",
       "         [139,  99, 153],\n",
       "         [127,  86, 148],\n",
       "         [117,  70, 130]],\n",
       "\n",
       "        [[120,  75, 125],\n",
       "         [181, 150, 190],\n",
       "         [184, 162, 198],\n",
       "         ...,\n",
       "         [153, 118, 173],\n",
       "         [140,  95, 162],\n",
       "         [111,  68, 134]]],\n",
       "\n",
       "\n",
       "       [[[224, 221, 232],\n",
       "         [215, 206, 219],\n",
       "         [199, 180, 198],\n",
       "         ...,\n",
       "         [141, 105, 182],\n",
       "         [151, 110, 184],\n",
       "         [107,  57, 112]],\n",
       "\n",
       "        [[134,  88, 144],\n",
       "         [152, 109, 158],\n",
       "         [152, 109, 160],\n",
       "         ...,\n",
       "         [150, 113, 192],\n",
       "         [141, 105, 167],\n",
       "         [131,  82, 136]],\n",
       "\n",
       "        [[115,  67, 145],\n",
       "         [ 98,  50,  98],\n",
       "         [115,  72, 134],\n",
       "         ...,\n",
       "         [142, 102, 177],\n",
       "         [145, 103, 180],\n",
       "         [132,  94, 163]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[175, 145, 188],\n",
       "         [179, 154, 182],\n",
       "         [143, 115, 149],\n",
       "         ...,\n",
       "         [116,  80, 178],\n",
       "         [115,  77, 168],\n",
       "         [114,  73, 154]],\n",
       "\n",
       "        [[127,  76, 144],\n",
       "         [100,  55, 104],\n",
       "         [115,  71, 136],\n",
       "         ...,\n",
       "         [119,  73, 160],\n",
       "         [119,  77, 167],\n",
       "         [115,  71, 150]],\n",
       "\n",
       "        [[ 77,  38,  95],\n",
       "         [ 82,  43, 100],\n",
       "         [115,  75, 146],\n",
       "         ...,\n",
       "         [126,  83, 139],\n",
       "         [124,  78, 157],\n",
       "         [111,  70, 145]]]], dtype=uint8)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-27T08:34:38.300738Z",
     "start_time": "2020-07-27T08:34:37.063056Z"
    }
   },
   "outputs": [],
   "source": [
    "X = X.astype(np.float32) #Casting the array to single precision takes half as much space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-27T07:52:42.018900Z",
     "start_time": "2020-07-27T07:52:42.009890Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[206., 164., 226.],\n",
       "         [196., 154., 224.],\n",
       "         [211., 175., 225.],\n",
       "         ...,\n",
       "         [237., 221., 240.],\n",
       "         [214., 184., 232.],\n",
       "         [235., 213., 243.]],\n",
       "\n",
       "        [[188., 142., 217.],\n",
       "         [179., 130., 221.],\n",
       "         [196., 150., 224.],\n",
       "         ...,\n",
       "         [204., 170., 227.],\n",
       "         [215., 180., 229.],\n",
       "         [232., 212., 236.]],\n",
       "\n",
       "        [[212., 178., 237.],\n",
       "         [199., 157., 229.],\n",
       "         [175., 125., 218.],\n",
       "         ...,\n",
       "         [217., 184., 221.],\n",
       "         [193., 153., 190.],\n",
       "         [208., 164., 227.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[192., 145., 217.],\n",
       "         [184., 129., 214.],\n",
       "         [183., 129., 212.],\n",
       "         ...,\n",
       "         [185., 122., 194.],\n",
       "         [193., 143., 204.],\n",
       "         [188., 129., 189.]],\n",
       "\n",
       "        [[192., 144., 218.],\n",
       "         [185., 128., 213.],\n",
       "         [171., 121., 208.],\n",
       "         ...,\n",
       "         [145.,  79., 136.],\n",
       "         [174., 111., 184.],\n",
       "         [176., 112., 188.]],\n",
       "\n",
       "        [[181., 125., 212.],\n",
       "         [181., 136., 211.],\n",
       "         [206., 162., 220.],\n",
       "         ...,\n",
       "         [152.,  90., 127.],\n",
       "         [202., 167., 213.],\n",
       "         [211., 180., 215.]]],\n",
       "\n",
       "\n",
       "       [[[197., 150., 219.],\n",
       "         [201., 158., 217.],\n",
       "         [205., 173., 228.],\n",
       "         ...,\n",
       "         [199., 165., 198.],\n",
       "         [224., 204., 230.],\n",
       "         [221., 193., 231.]],\n",
       "\n",
       "        [[195., 150., 223.],\n",
       "         [192., 140., 222.],\n",
       "         [186., 133., 213.],\n",
       "         ...,\n",
       "         [193., 143., 218.],\n",
       "         [197., 148., 218.],\n",
       "         [185., 131., 215.]],\n",
       "\n",
       "        [[176., 125., 203.],\n",
       "         [192., 143., 218.],\n",
       "         [199., 163., 227.],\n",
       "         ...,\n",
       "         [188., 137., 210.],\n",
       "         [177., 121., 203.],\n",
       "         [183., 124., 192.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[242., 234., 247.],\n",
       "         [248., 249., 247.],\n",
       "         [247., 247., 248.],\n",
       "         ...,\n",
       "         [242., 240., 245.],\n",
       "         [247., 244., 249.],\n",
       "         [239., 234., 243.]],\n",
       "\n",
       "        [[246., 243., 249.],\n",
       "         [247., 240., 243.],\n",
       "         [246., 241., 248.],\n",
       "         ...,\n",
       "         [251., 247., 247.],\n",
       "         [246., 244., 247.],\n",
       "         [251., 246., 249.]],\n",
       "\n",
       "        [[226., 204., 230.],\n",
       "         [244., 247., 246.],\n",
       "         [249., 245., 250.],\n",
       "         ...,\n",
       "         [250., 243., 249.],\n",
       "         [248., 248., 251.],\n",
       "         [247., 247., 248.]]],\n",
       "\n",
       "\n",
       "       [[[249., 245., 248.],\n",
       "         [248., 246., 248.],\n",
       "         [253., 246., 249.],\n",
       "         ...,\n",
       "         [248., 249., 249.],\n",
       "         [249., 246., 247.],\n",
       "         [248., 244., 248.]],\n",
       "\n",
       "        [[246., 246., 248.],\n",
       "         [247., 245., 248.],\n",
       "         [248., 248., 250.],\n",
       "         ...,\n",
       "         [246., 243., 249.],\n",
       "         [247., 244., 252.],\n",
       "         [247., 250., 249.]],\n",
       "\n",
       "        [[238., 231., 241.],\n",
       "         [240., 225., 239.],\n",
       "         [242., 237., 243.],\n",
       "         ...,\n",
       "         [251., 244., 248.],\n",
       "         [249., 248., 245.],\n",
       "         [251., 242., 249.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[249., 247., 248.],\n",
       "         [249., 247., 248.],\n",
       "         [249., 247., 248.],\n",
       "         ...,\n",
       "         [245., 242., 245.],\n",
       "         [238., 227., 241.],\n",
       "         [203., 159., 216.]],\n",
       "\n",
       "        [[249., 247., 248.],\n",
       "         [249., 247., 248.],\n",
       "         [249., 247., 249.],\n",
       "         ...,\n",
       "         [249., 242., 249.],\n",
       "         [222., 193., 229.],\n",
       "         [171., 111., 161.]],\n",
       "\n",
       "        [[249., 247., 249.],\n",
       "         [249., 247., 249.],\n",
       "         [249., 247., 249.],\n",
       "         ...,\n",
       "         [247., 248., 247.],\n",
       "         [230., 210., 235.],\n",
       "         [177., 120., 186.]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[ 93.,  47.,  96.],\n",
       "         [104.,  56., 118.],\n",
       "         [116.,  64., 120.],\n",
       "         ...,\n",
       "         [110.,  63., 130.],\n",
       "         [115.,  80., 172.],\n",
       "         [120.,  85., 168.]],\n",
       "\n",
       "        [[106.,  53., 103.],\n",
       "         [ 83.,  30.,  72.],\n",
       "         [102.,  53.,  94.],\n",
       "         ...,\n",
       "         [116.,  79., 187.],\n",
       "         [139., 102., 186.],\n",
       "         [148., 109., 170.]],\n",
       "\n",
       "        [[112.,  59., 108.],\n",
       "         [103.,  54., 109.],\n",
       "         [124.,  82., 129.],\n",
       "         ...,\n",
       "         [127.,  85., 171.],\n",
       "         [132.,  92., 175.],\n",
       "         [ 97.,  59., 123.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[133.,  88., 163.],\n",
       "         [120.,  76., 155.],\n",
       "         [111.,  67., 155.],\n",
       "         ...,\n",
       "         [170., 145., 195.],\n",
       "         [130.,  87., 126.],\n",
       "         [120.,  80., 156.]],\n",
       "\n",
       "        [[ 98.,  49.,  98.],\n",
       "         [103.,  57., 107.],\n",
       "         [129.,  79., 138.],\n",
       "         ...,\n",
       "         [149., 112., 175.],\n",
       "         [118.,  79., 182.],\n",
       "         [111.,  67., 149.]],\n",
       "\n",
       "        [[ 86.,  46.,  97.],\n",
       "         [ 82.,  33.,  73.],\n",
       "         [ 76.,  32.,  72.],\n",
       "         ...,\n",
       "         [160., 123., 172.],\n",
       "         [103.,  62., 148.],\n",
       "         [105.,  69., 169.]]],\n",
       "\n",
       "\n",
       "       [[[110.,  65., 148.],\n",
       "         [111.,  70., 144.],\n",
       "         [107.,  63., 139.],\n",
       "         ...,\n",
       "         [117.,  72., 154.],\n",
       "         [103.,  68., 162.],\n",
       "         [110.,  72., 159.]],\n",
       "\n",
       "        [[106.,  63., 136.],\n",
       "         [109.,  65., 154.],\n",
       "         [122.,  80., 163.],\n",
       "         ...,\n",
       "         [122.,  82., 161.],\n",
       "         [126.,  84., 158.],\n",
       "         [125.,  82., 156.]],\n",
       "\n",
       "        [[149., 111., 175.],\n",
       "         [143., 100., 160.],\n",
       "         [123.,  84., 131.],\n",
       "         ...,\n",
       "         [112.,  67., 138.],\n",
       "         [116.,  71., 143.],\n",
       "         [117.,  76., 161.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 69.,  27.,  58.],\n",
       "         [ 60.,  21.,  55.],\n",
       "         [ 44.,  10.,  32.],\n",
       "         ...,\n",
       "         [104.,  53., 106.],\n",
       "         [126.,  84., 146.],\n",
       "         [132.,  94., 179.]],\n",
       "\n",
       "        [[ 67.,  27.,  57.],\n",
       "         [159., 135., 165.],\n",
       "         [ 79.,  47.,  77.],\n",
       "         ...,\n",
       "         [139.,  99., 153.],\n",
       "         [127.,  86., 148.],\n",
       "         [117.,  70., 130.]],\n",
       "\n",
       "        [[120.,  75., 125.],\n",
       "         [181., 150., 190.],\n",
       "         [184., 162., 198.],\n",
       "         ...,\n",
       "         [153., 118., 173.],\n",
       "         [140.,  95., 162.],\n",
       "         [111.,  68., 134.]]],\n",
       "\n",
       "\n",
       "       [[[224., 221., 232.],\n",
       "         [215., 206., 219.],\n",
       "         [199., 180., 198.],\n",
       "         ...,\n",
       "         [141., 105., 182.],\n",
       "         [151., 110., 184.],\n",
       "         [107.,  57., 112.]],\n",
       "\n",
       "        [[134.,  88., 144.],\n",
       "         [152., 109., 158.],\n",
       "         [152., 109., 160.],\n",
       "         ...,\n",
       "         [150., 113., 192.],\n",
       "         [141., 105., 167.],\n",
       "         [131.,  82., 136.]],\n",
       "\n",
       "        [[115.,  67., 145.],\n",
       "         [ 98.,  50.,  98.],\n",
       "         [115.,  72., 134.],\n",
       "         ...,\n",
       "         [142., 102., 177.],\n",
       "         [145., 103., 180.],\n",
       "         [132.,  94., 163.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[175., 145., 188.],\n",
       "         [179., 154., 182.],\n",
       "         [143., 115., 149.],\n",
       "         ...,\n",
       "         [116.,  80., 178.],\n",
       "         [115.,  77., 168.],\n",
       "         [114.,  73., 154.]],\n",
       "\n",
       "        [[127.,  76., 144.],\n",
       "         [100.,  55., 104.],\n",
       "         [115.,  71., 136.],\n",
       "         ...,\n",
       "         [119.,  73., 160.],\n",
       "         [119.,  77., 167.],\n",
       "         [115.,  71., 150.]],\n",
       "\n",
       "        [[ 77.,  38.,  95.],\n",
       "         [ 82.,  43., 100.],\n",
       "         [115.,  75., 146.],\n",
       "         ...,\n",
       "         [126.,  83., 139.],\n",
       "         [124.,  78., 157.],\n",
       "         [111.,  70., 145.]]]], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The images are normalized by dividing it by 255. This ensures all the values are between 0 and 1. This will help to train the model faster and prevent the vanishing and the exploding gradient problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-27T08:34:41.885981Z",
     "start_time": "2020-07-27T08:34:41.574148Z"
    }
   },
   "outputs": [],
   "source": [
    "X /= 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-27T07:52:49.134443Z",
     "start_time": "2020-07-27T07:52:49.125461Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[0.80784315, 0.6431373 , 0.8862745 ],\n",
       "         [0.76862746, 0.6039216 , 0.8784314 ],\n",
       "         [0.827451  , 0.6862745 , 0.88235295],\n",
       "         ...,\n",
       "         [0.92941177, 0.8666667 , 0.9411765 ],\n",
       "         [0.8392157 , 0.72156864, 0.9098039 ],\n",
       "         [0.92156863, 0.8352941 , 0.9529412 ]],\n",
       "\n",
       "        [[0.7372549 , 0.5568628 , 0.8509804 ],\n",
       "         [0.7019608 , 0.50980395, 0.8666667 ],\n",
       "         [0.76862746, 0.5882353 , 0.8784314 ],\n",
       "         ...,\n",
       "         [0.8       , 0.6666667 , 0.8901961 ],\n",
       "         [0.84313726, 0.7058824 , 0.8980392 ],\n",
       "         [0.9098039 , 0.83137256, 0.9254902 ]],\n",
       "\n",
       "        [[0.83137256, 0.69803923, 0.92941177],\n",
       "         [0.78039217, 0.6156863 , 0.8980392 ],\n",
       "         [0.6862745 , 0.49019608, 0.85490197],\n",
       "         ...,\n",
       "         [0.8509804 , 0.72156864, 0.8666667 ],\n",
       "         [0.75686276, 0.6       , 0.74509805],\n",
       "         [0.8156863 , 0.6431373 , 0.8901961 ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.7529412 , 0.5686275 , 0.8509804 ],\n",
       "         [0.72156864, 0.5058824 , 0.8392157 ],\n",
       "         [0.7176471 , 0.5058824 , 0.83137256],\n",
       "         ...,\n",
       "         [0.7254902 , 0.47843137, 0.7607843 ],\n",
       "         [0.75686276, 0.56078434, 0.8       ],\n",
       "         [0.7372549 , 0.5058824 , 0.7411765 ]],\n",
       "\n",
       "        [[0.7529412 , 0.5647059 , 0.85490197],\n",
       "         [0.7254902 , 0.5019608 , 0.8352941 ],\n",
       "         [0.67058825, 0.4745098 , 0.8156863 ],\n",
       "         ...,\n",
       "         [0.5686275 , 0.30980393, 0.53333336],\n",
       "         [0.68235296, 0.43529412, 0.72156864],\n",
       "         [0.6901961 , 0.4392157 , 0.7372549 ]],\n",
       "\n",
       "        [[0.70980394, 0.49019608, 0.83137256],\n",
       "         [0.70980394, 0.53333336, 0.827451  ],\n",
       "         [0.80784315, 0.63529414, 0.8627451 ],\n",
       "         ...,\n",
       "         [0.59607846, 0.3529412 , 0.49803922],\n",
       "         [0.7921569 , 0.654902  , 0.8352941 ],\n",
       "         [0.827451  , 0.7058824 , 0.84313726]]],\n",
       "\n",
       "\n",
       "       [[[0.77254903, 0.5882353 , 0.85882354],\n",
       "         [0.7882353 , 0.61960787, 0.8509804 ],\n",
       "         [0.8039216 , 0.6784314 , 0.89411765],\n",
       "         ...,\n",
       "         [0.78039217, 0.64705884, 0.7764706 ],\n",
       "         [0.8784314 , 0.8       , 0.9019608 ],\n",
       "         [0.8666667 , 0.75686276, 0.90588236]],\n",
       "\n",
       "        [[0.7647059 , 0.5882353 , 0.8745098 ],\n",
       "         [0.7529412 , 0.54901963, 0.87058824],\n",
       "         [0.7294118 , 0.52156866, 0.8352941 ],\n",
       "         ...,\n",
       "         [0.75686276, 0.56078434, 0.85490197],\n",
       "         [0.77254903, 0.5803922 , 0.85490197],\n",
       "         [0.7254902 , 0.5137255 , 0.84313726]],\n",
       "\n",
       "        [[0.6901961 , 0.49019608, 0.79607844],\n",
       "         [0.7529412 , 0.56078434, 0.85490197],\n",
       "         [0.78039217, 0.6392157 , 0.8901961 ],\n",
       "         ...,\n",
       "         [0.7372549 , 0.5372549 , 0.8235294 ],\n",
       "         [0.69411767, 0.4745098 , 0.79607844],\n",
       "         [0.7176471 , 0.4862745 , 0.7529412 ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.9490196 , 0.91764706, 0.96862745],\n",
       "         [0.972549  , 0.9764706 , 0.96862745],\n",
       "         [0.96862745, 0.96862745, 0.972549  ],\n",
       "         ...,\n",
       "         [0.9490196 , 0.9411765 , 0.9607843 ],\n",
       "         [0.96862745, 0.95686275, 0.9764706 ],\n",
       "         [0.9372549 , 0.91764706, 0.9529412 ]],\n",
       "\n",
       "        [[0.9647059 , 0.9529412 , 0.9764706 ],\n",
       "         [0.96862745, 0.9411765 , 0.9529412 ],\n",
       "         [0.9647059 , 0.94509804, 0.972549  ],\n",
       "         ...,\n",
       "         [0.9843137 , 0.96862745, 0.96862745],\n",
       "         [0.9647059 , 0.95686275, 0.96862745],\n",
       "         [0.9843137 , 0.9647059 , 0.9764706 ]],\n",
       "\n",
       "        [[0.8862745 , 0.8       , 0.9019608 ],\n",
       "         [0.95686275, 0.96862745, 0.9647059 ],\n",
       "         [0.9764706 , 0.9607843 , 0.98039216],\n",
       "         ...,\n",
       "         [0.98039216, 0.9529412 , 0.9764706 ],\n",
       "         [0.972549  , 0.972549  , 0.9843137 ],\n",
       "         [0.96862745, 0.96862745, 0.972549  ]]],\n",
       "\n",
       "\n",
       "       [[[0.9764706 , 0.9607843 , 0.972549  ],\n",
       "         [0.972549  , 0.9647059 , 0.972549  ],\n",
       "         [0.99215686, 0.9647059 , 0.9764706 ],\n",
       "         ...,\n",
       "         [0.972549  , 0.9764706 , 0.9764706 ],\n",
       "         [0.9764706 , 0.9647059 , 0.96862745],\n",
       "         [0.972549  , 0.95686275, 0.972549  ]],\n",
       "\n",
       "        [[0.9647059 , 0.9647059 , 0.972549  ],\n",
       "         [0.96862745, 0.9607843 , 0.972549  ],\n",
       "         [0.972549  , 0.972549  , 0.98039216],\n",
       "         ...,\n",
       "         [0.9647059 , 0.9529412 , 0.9764706 ],\n",
       "         [0.96862745, 0.95686275, 0.9882353 ],\n",
       "         [0.96862745, 0.98039216, 0.9764706 ]],\n",
       "\n",
       "        [[0.93333334, 0.90588236, 0.94509804],\n",
       "         [0.9411765 , 0.88235295, 0.9372549 ],\n",
       "         [0.9490196 , 0.92941177, 0.9529412 ],\n",
       "         ...,\n",
       "         [0.9843137 , 0.95686275, 0.972549  ],\n",
       "         [0.9764706 , 0.972549  , 0.9607843 ],\n",
       "         [0.9843137 , 0.9490196 , 0.9764706 ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.9764706 , 0.96862745, 0.972549  ],\n",
       "         [0.9764706 , 0.96862745, 0.972549  ],\n",
       "         [0.9764706 , 0.96862745, 0.972549  ],\n",
       "         ...,\n",
       "         [0.9607843 , 0.9490196 , 0.9607843 ],\n",
       "         [0.93333334, 0.8901961 , 0.94509804],\n",
       "         [0.79607844, 0.62352943, 0.84705883]],\n",
       "\n",
       "        [[0.9764706 , 0.96862745, 0.972549  ],\n",
       "         [0.9764706 , 0.96862745, 0.972549  ],\n",
       "         [0.9764706 , 0.96862745, 0.9764706 ],\n",
       "         ...,\n",
       "         [0.9764706 , 0.9490196 , 0.9764706 ],\n",
       "         [0.87058824, 0.75686276, 0.8980392 ],\n",
       "         [0.67058825, 0.43529412, 0.6313726 ]],\n",
       "\n",
       "        [[0.9764706 , 0.96862745, 0.9764706 ],\n",
       "         [0.9764706 , 0.96862745, 0.9764706 ],\n",
       "         [0.9764706 , 0.96862745, 0.9764706 ],\n",
       "         ...,\n",
       "         [0.96862745, 0.972549  , 0.96862745],\n",
       "         [0.9019608 , 0.8235294 , 0.92156863],\n",
       "         [0.69411767, 0.47058824, 0.7294118 ]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[0.3647059 , 0.18431373, 0.3764706 ],\n",
       "         [0.40784314, 0.21960784, 0.4627451 ],\n",
       "         [0.45490196, 0.2509804 , 0.47058824],\n",
       "         ...,\n",
       "         [0.43137255, 0.24705882, 0.50980395],\n",
       "         [0.4509804 , 0.3137255 , 0.6745098 ],\n",
       "         [0.47058824, 0.33333334, 0.65882355]],\n",
       "\n",
       "        [[0.41568628, 0.20784314, 0.40392157],\n",
       "         [0.3254902 , 0.11764706, 0.28235295],\n",
       "         [0.4       , 0.20784314, 0.36862746],\n",
       "         ...,\n",
       "         [0.45490196, 0.30980393, 0.73333335],\n",
       "         [0.54509807, 0.4       , 0.7294118 ],\n",
       "         [0.5803922 , 0.42745098, 0.6666667 ]],\n",
       "\n",
       "        [[0.4392157 , 0.23137255, 0.42352942],\n",
       "         [0.40392157, 0.21176471, 0.42745098],\n",
       "         [0.4862745 , 0.32156864, 0.5058824 ],\n",
       "         ...,\n",
       "         [0.49803922, 0.33333334, 0.67058825],\n",
       "         [0.5176471 , 0.36078432, 0.6862745 ],\n",
       "         [0.38039216, 0.23137255, 0.48235294]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.52156866, 0.34509805, 0.6392157 ],\n",
       "         [0.47058824, 0.29803923, 0.60784316],\n",
       "         [0.43529412, 0.2627451 , 0.60784316],\n",
       "         ...,\n",
       "         [0.6666667 , 0.5686275 , 0.7647059 ],\n",
       "         [0.50980395, 0.34117648, 0.49411765],\n",
       "         [0.47058824, 0.3137255 , 0.6117647 ]],\n",
       "\n",
       "        [[0.38431373, 0.19215687, 0.38431373],\n",
       "         [0.40392157, 0.22352941, 0.41960785],\n",
       "         [0.5058824 , 0.30980393, 0.5411765 ],\n",
       "         ...,\n",
       "         [0.58431375, 0.4392157 , 0.6862745 ],\n",
       "         [0.4627451 , 0.30980393, 0.7137255 ],\n",
       "         [0.43529412, 0.2627451 , 0.58431375]],\n",
       "\n",
       "        [[0.3372549 , 0.18039216, 0.38039216],\n",
       "         [0.32156864, 0.12941177, 0.28627452],\n",
       "         [0.29803923, 0.1254902 , 0.28235295],\n",
       "         ...,\n",
       "         [0.627451  , 0.48235294, 0.6745098 ],\n",
       "         [0.40392157, 0.24313726, 0.5803922 ],\n",
       "         [0.4117647 , 0.27058825, 0.6627451 ]]],\n",
       "\n",
       "\n",
       "       [[[0.43137255, 0.25490198, 0.5803922 ],\n",
       "         [0.43529412, 0.27450982, 0.5647059 ],\n",
       "         [0.41960785, 0.24705882, 0.54509807],\n",
       "         ...,\n",
       "         [0.45882353, 0.28235295, 0.6039216 ],\n",
       "         [0.40392157, 0.26666668, 0.63529414],\n",
       "         [0.43137255, 0.28235295, 0.62352943]],\n",
       "\n",
       "        [[0.41568628, 0.24705882, 0.53333336],\n",
       "         [0.42745098, 0.25490198, 0.6039216 ],\n",
       "         [0.47843137, 0.3137255 , 0.6392157 ],\n",
       "         ...,\n",
       "         [0.47843137, 0.32156864, 0.6313726 ],\n",
       "         [0.49411765, 0.32941177, 0.61960787],\n",
       "         [0.49019608, 0.32156864, 0.6117647 ]],\n",
       "\n",
       "        [[0.58431375, 0.43529412, 0.6862745 ],\n",
       "         [0.56078434, 0.39215687, 0.627451  ],\n",
       "         [0.48235294, 0.32941177, 0.5137255 ],\n",
       "         ...,\n",
       "         [0.4392157 , 0.2627451 , 0.5411765 ],\n",
       "         [0.45490196, 0.2784314 , 0.56078434],\n",
       "         [0.45882353, 0.29803923, 0.6313726 ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.27058825, 0.10588235, 0.22745098],\n",
       "         [0.23529412, 0.08235294, 0.21568628],\n",
       "         [0.17254902, 0.03921569, 0.1254902 ],\n",
       "         ...,\n",
       "         [0.40784314, 0.20784314, 0.41568628],\n",
       "         [0.49411765, 0.32941177, 0.57254905],\n",
       "         [0.5176471 , 0.36862746, 0.7019608 ]],\n",
       "\n",
       "        [[0.2627451 , 0.10588235, 0.22352941],\n",
       "         [0.62352943, 0.5294118 , 0.64705884],\n",
       "         [0.30980393, 0.18431373, 0.3019608 ],\n",
       "         ...,\n",
       "         [0.54509807, 0.3882353 , 0.6       ],\n",
       "         [0.49803922, 0.3372549 , 0.5803922 ],\n",
       "         [0.45882353, 0.27450982, 0.50980395]],\n",
       "\n",
       "        [[0.47058824, 0.29411766, 0.49019608],\n",
       "         [0.70980394, 0.5882353 , 0.74509805],\n",
       "         [0.72156864, 0.63529414, 0.7764706 ],\n",
       "         ...,\n",
       "         [0.6       , 0.4627451 , 0.6784314 ],\n",
       "         [0.54901963, 0.37254903, 0.63529414],\n",
       "         [0.43529412, 0.26666668, 0.5254902 ]]],\n",
       "\n",
       "\n",
       "       [[[0.8784314 , 0.8666667 , 0.9098039 ],\n",
       "         [0.84313726, 0.80784315, 0.85882354],\n",
       "         [0.78039217, 0.7058824 , 0.7764706 ],\n",
       "         ...,\n",
       "         [0.5529412 , 0.4117647 , 0.7137255 ],\n",
       "         [0.5921569 , 0.43137255, 0.72156864],\n",
       "         [0.41960785, 0.22352941, 0.4392157 ]],\n",
       "\n",
       "        [[0.5254902 , 0.34509805, 0.5647059 ],\n",
       "         [0.59607846, 0.42745098, 0.61960787],\n",
       "         [0.59607846, 0.42745098, 0.627451  ],\n",
       "         ...,\n",
       "         [0.5882353 , 0.44313726, 0.7529412 ],\n",
       "         [0.5529412 , 0.4117647 , 0.654902  ],\n",
       "         [0.5137255 , 0.32156864, 0.53333336]],\n",
       "\n",
       "        [[0.4509804 , 0.2627451 , 0.5686275 ],\n",
       "         [0.38431373, 0.19607843, 0.38431373],\n",
       "         [0.4509804 , 0.28235295, 0.5254902 ],\n",
       "         ...,\n",
       "         [0.5568628 , 0.4       , 0.69411767],\n",
       "         [0.5686275 , 0.40392157, 0.7058824 ],\n",
       "         [0.5176471 , 0.36862746, 0.6392157 ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.6862745 , 0.5686275 , 0.7372549 ],\n",
       "         [0.7019608 , 0.6039216 , 0.7137255 ],\n",
       "         [0.56078434, 0.4509804 , 0.58431375],\n",
       "         ...,\n",
       "         [0.45490196, 0.3137255 , 0.69803923],\n",
       "         [0.4509804 , 0.3019608 , 0.65882355],\n",
       "         [0.44705883, 0.28627452, 0.6039216 ]],\n",
       "\n",
       "        [[0.49803922, 0.29803923, 0.5647059 ],\n",
       "         [0.39215687, 0.21568628, 0.40784314],\n",
       "         [0.4509804 , 0.2784314 , 0.53333336],\n",
       "         ...,\n",
       "         [0.46666667, 0.28627452, 0.627451  ],\n",
       "         [0.46666667, 0.3019608 , 0.654902  ],\n",
       "         [0.4509804 , 0.2784314 , 0.5882353 ]],\n",
       "\n",
       "        [[0.3019608 , 0.14901961, 0.37254903],\n",
       "         [0.32156864, 0.16862746, 0.39215687],\n",
       "         [0.4509804 , 0.29411766, 0.57254905],\n",
       "         ...,\n",
       "         [0.49411765, 0.3254902 , 0.54509807],\n",
       "         [0.4862745 , 0.30588236, 0.6156863 ],\n",
       "         [0.43529412, 0.27450982, 0.5686275 ]]]], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The resulting dataset is split into training and testing set, with 15 percent of the entire dataset reserved for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-27T08:34:50.671321Z",
     "start_time": "2020-07-27T08:34:46.861766Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,Y,test_size=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-27T07:52:59.089359Z",
     "start_time": "2020-07-27T07:52:59.079385Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[0.69803923, 0.5803922 , 0.7019608 ],\n",
       "         [0.7294118 , 0.654902  , 0.8509804 ],\n",
       "         [0.8862745 , 0.85882354, 0.9254902 ],\n",
       "         ...,\n",
       "         [0.7607843 , 0.67058825, 0.8666667 ],\n",
       "         [0.7529412 , 0.6627451 , 0.8509804 ],\n",
       "         [0.7137255 , 0.5764706 , 0.8039216 ]],\n",
       "\n",
       "        [[0.8039216 , 0.74509805, 0.84313726],\n",
       "         [0.84705883, 0.8       , 0.91764706],\n",
       "         [0.9254902 , 0.9254902 , 0.9490196 ],\n",
       "         ...,\n",
       "         [0.7529412 , 0.65882355, 0.85882354],\n",
       "         [0.74509805, 0.6431373 , 0.8666667 ],\n",
       "         [0.7647059 , 0.67058825, 0.8392157 ]],\n",
       "\n",
       "        [[0.8862745 , 0.8666667 , 0.9137255 ],\n",
       "         [0.9254902 , 0.90588236, 0.9372549 ],\n",
       "         [0.92941177, 0.91764706, 0.9372549 ],\n",
       "         ...,\n",
       "         [0.7529412 , 0.6431373 , 0.87058824],\n",
       "         [0.74509805, 0.6509804 , 0.8666667 ],\n",
       "         [0.73333335, 0.63529414, 0.8627451 ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.8       , 0.70980394, 0.85882354],\n",
       "         [0.8039216 , 0.7294118 , 0.89411765],\n",
       "         [0.79607844, 0.7254902 , 0.8784314 ],\n",
       "         ...,\n",
       "         [0.80784315, 0.7137255 , 0.89411765],\n",
       "         [0.77254903, 0.6901961 , 0.8745098 ],\n",
       "         [0.78431374, 0.69411767, 0.89411765]],\n",
       "\n",
       "        [[0.7058824 , 0.6039216 , 0.8039216 ],\n",
       "         [0.7490196 , 0.6431373 , 0.8392157 ],\n",
       "         [0.83137256, 0.7764706 , 0.8745098 ],\n",
       "         ...,\n",
       "         [0.7411765 , 0.64705884, 0.8745098 ],\n",
       "         [0.78039217, 0.6862745 , 0.8666667 ],\n",
       "         [0.77254903, 0.6901961 , 0.87058824]],\n",
       "\n",
       "        [[0.8235294 , 0.7529412 , 0.8980392 ],\n",
       "         [0.8235294 , 0.75686276, 0.89411765],\n",
       "         [0.65882355, 0.5294118 , 0.6627451 ],\n",
       "         ...,\n",
       "         [0.73333335, 0.64705884, 0.89411765],\n",
       "         [0.7372549 , 0.6       , 0.81960785],\n",
       "         [0.7254902 , 0.627451  , 0.8627451 ]]],\n",
       "\n",
       "\n",
       "       [[[0.8392157 , 0.7882353 , 0.8901961 ],\n",
       "         [0.7882353 , 0.69411767, 0.8627451 ],\n",
       "         [0.8117647 , 0.72156864, 0.88235295],\n",
       "         ...,\n",
       "         [0.7921569 , 0.7019608 , 0.8745098 ],\n",
       "         [0.61960787, 0.4745098 , 0.6627451 ],\n",
       "         [0.827451  , 0.7529412 , 0.8745098 ]],\n",
       "\n",
       "        [[0.92156863, 0.91764706, 0.9490196 ],\n",
       "         [0.92156863, 0.90588236, 0.92941177],\n",
       "         [0.85882354, 0.8       , 0.8862745 ],\n",
       "         ...,\n",
       "         [0.8235294 , 0.7411765 , 0.88235295],\n",
       "         [0.8039216 , 0.7176471 , 0.85490197],\n",
       "         [0.7254902 , 0.6       , 0.8509804 ]],\n",
       "\n",
       "        [[0.92156863, 0.8784314 , 0.91764706],\n",
       "         [0.92941177, 0.91764706, 0.93333334],\n",
       "         [0.92941177, 0.92941177, 0.9372549 ],\n",
       "         ...,\n",
       "         [0.8392157 , 0.78431374, 0.8862745 ],\n",
       "         [0.89411765, 0.8862745 , 0.9137255 ],\n",
       "         [0.8392157 , 0.78431374, 0.8901961 ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.93333334, 0.93333334, 0.94509804],\n",
       "         [0.9372549 , 0.93333334, 0.94509804],\n",
       "         [0.9372549 , 0.92156863, 0.94509804],\n",
       "         ...,\n",
       "         [0.9372549 , 0.9254902 , 0.93333334],\n",
       "         [0.92941177, 0.91764706, 0.9254902 ],\n",
       "         [0.9372549 , 0.93333334, 0.9254902 ]],\n",
       "\n",
       "        [[0.9372549 , 0.92941177, 0.94509804],\n",
       "         [0.9372549 , 0.92941177, 0.94509804],\n",
       "         [0.9372549 , 0.92941177, 0.94509804],\n",
       "         ...,\n",
       "         [0.93333334, 0.9254902 , 0.92941177],\n",
       "         [0.9372549 , 0.9254902 , 0.92941177],\n",
       "         [0.9372549 , 0.92941177, 0.93333334]],\n",
       "\n",
       "        [[0.9372549 , 0.93333334, 0.94509804],\n",
       "         [0.9372549 , 0.93333334, 0.94509804],\n",
       "         [0.9372549 , 0.93333334, 0.94509804],\n",
       "         ...,\n",
       "         [0.9372549 , 0.9254902 , 0.92941177],\n",
       "         [0.9372549 , 0.92941177, 0.92941177],\n",
       "         [0.9372549 , 0.92941177, 0.93333334]]],\n",
       "\n",
       "\n",
       "       [[[0.9490196 , 0.9372549 , 0.9529412 ],\n",
       "         [0.9490196 , 0.94509804, 0.9490196 ],\n",
       "         [0.94509804, 0.9529412 , 0.9529412 ],\n",
       "         ...,\n",
       "         [0.60784316, 0.3882353 , 0.7490196 ],\n",
       "         [0.68235296, 0.49803922, 0.79607844],\n",
       "         [0.6784314 , 0.5019608 , 0.69803923]],\n",
       "\n",
       "        [[0.9529412 , 0.9490196 , 0.95686275],\n",
       "         [0.95686275, 0.9529412 , 0.9490196 ],\n",
       "         [0.9529412 , 0.9411765 , 0.9529412 ],\n",
       "         ...,\n",
       "         [0.65882355, 0.49411765, 0.8039216 ],\n",
       "         [0.6039216 , 0.40392157, 0.73333335],\n",
       "         [0.7372549 , 0.58431375, 0.8392157 ]],\n",
       "\n",
       "        [[0.9529412 , 0.9490196 , 0.95686275],\n",
       "         [0.9529412 , 0.95686275, 0.9490196 ],\n",
       "         [0.9529412 , 0.94509804, 0.95686275],\n",
       "         ...,\n",
       "         [0.7176471 , 0.5529412 , 0.8235294 ],\n",
       "         [0.69803923, 0.5137255 , 0.81960785],\n",
       "         [0.7137255 , 0.56078434, 0.83137256]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.9529412 , 0.9490196 , 0.95686275],\n",
       "         [0.9647059 , 0.9529412 , 0.9490196 ],\n",
       "         [0.9490196 , 0.94509804, 0.9490196 ],\n",
       "         ...,\n",
       "         [0.8901961 , 0.84313726, 0.9019608 ],\n",
       "         [0.9372549 , 0.93333334, 0.94509804],\n",
       "         [0.9372549 , 0.90588236, 0.91764706]],\n",
       "\n",
       "        [[0.9490196 , 0.9372549 , 0.9529412 ],\n",
       "         [0.9411765 , 0.94509804, 0.9490196 ],\n",
       "         [0.9529412 , 0.94509804, 0.9529412 ],\n",
       "         ...,\n",
       "         [0.91764706, 0.89411765, 0.9411765 ],\n",
       "         [0.9254902 , 0.8980392 , 0.92941177],\n",
       "         [0.9137255 , 0.90588236, 0.9490196 ]],\n",
       "\n",
       "        [[0.9529412 , 0.9490196 , 0.9529412 ],\n",
       "         [0.95686275, 0.94509804, 0.9529412 ],\n",
       "         [0.9529412 , 0.9490196 , 0.9529412 ],\n",
       "         ...,\n",
       "         [0.8039216 , 0.69411767, 0.827451  ],\n",
       "         [0.85882354, 0.79607844, 0.89411765],\n",
       "         [0.78039217, 0.63529414, 0.827451  ]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[0.78431374, 0.6745098 , 0.8352941 ],\n",
       "         [0.9254902 , 0.88235295, 0.93333334],\n",
       "         [0.7764706 , 0.6745098 , 0.7176471 ],\n",
       "         ...,\n",
       "         [0.77254903, 0.6313726 , 0.87058824],\n",
       "         [0.6431373 , 0.43137255, 0.7372549 ],\n",
       "         [0.5058824 , 0.27450982, 0.4509804 ]],\n",
       "\n",
       "        [[0.49803922, 0.2784314 , 0.47058824],\n",
       "         [0.627451  , 0.40392157, 0.6313726 ],\n",
       "         [0.5686275 , 0.35686275, 0.49803922],\n",
       "         ...,\n",
       "         [0.7647059 , 0.5882353 , 0.827451  ],\n",
       "         [0.60784316, 0.39215687, 0.6627451 ],\n",
       "         [0.54901963, 0.33333334, 0.50980395]],\n",
       "\n",
       "        [[0.7176471 , 0.5137255 , 0.76862746],\n",
       "         [0.77254903, 0.6509804 , 0.8156863 ],\n",
       "         [0.75686276, 0.627451  , 0.7882353 ],\n",
       "         ...,\n",
       "         [0.7647059 , 0.6392157 , 0.8352941 ],\n",
       "         [0.7137255 , 0.5372549 , 0.7372549 ],\n",
       "         [0.7137255 , 0.5411765 , 0.7372549 ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.7058824 , 0.49803922, 0.7921569 ],\n",
       "         [0.7019608 , 0.49803922, 0.7372549 ],\n",
       "         [0.68235296, 0.49411765, 0.7764706 ],\n",
       "         ...,\n",
       "         [0.64705884, 0.44705883, 0.7921569 ],\n",
       "         [0.6901961 , 0.5176471 , 0.8627451 ],\n",
       "         [0.6117647 , 0.40392157, 0.7882353 ]],\n",
       "\n",
       "        [[0.68235296, 0.52156866, 0.69411767],\n",
       "         [0.6666667 , 0.4509804 , 0.70980394],\n",
       "         [0.6666667 , 0.5058824 , 0.7764706 ],\n",
       "         ...,\n",
       "         [0.60784316, 0.43137255, 0.8       ],\n",
       "         [0.654902  , 0.4509804 , 0.84313726],\n",
       "         [0.6       , 0.37254903, 0.79607844]],\n",
       "\n",
       "        [[0.6666667 , 0.48235294, 0.7137255 ],\n",
       "         [0.6784314 , 0.49411765, 0.7647059 ],\n",
       "         [0.6666667 , 0.45490196, 0.80784315],\n",
       "         ...,\n",
       "         [0.65882355, 0.46666667, 0.7921569 ],\n",
       "         [0.7372549 , 0.56078434, 0.8627451 ],\n",
       "         [0.5921569 , 0.39215687, 0.80784315]]],\n",
       "\n",
       "\n",
       "       [[[0.7529412 , 0.6392157 , 0.85882354],\n",
       "         [0.8117647 , 0.7019608 , 0.8980392 ],\n",
       "         [0.75686276, 0.6392157 , 0.8745098 ],\n",
       "         ...,\n",
       "         [0.7176471 , 0.61960787, 0.8784314 ],\n",
       "         [0.5568628 , 0.39215687, 0.8235294 ],\n",
       "         [0.5137255 , 0.34117648, 0.8117647 ]],\n",
       "\n",
       "        [[0.91764706, 0.9019608 , 0.9411765 ],\n",
       "         [0.90588236, 0.8745098 , 0.9411765 ],\n",
       "         [0.78039217, 0.6666667 , 0.89411765],\n",
       "         ...,\n",
       "         [0.5411765 , 0.4117647 , 0.7882353 ],\n",
       "         [0.63529414, 0.48235294, 0.84705883],\n",
       "         [0.49803922, 0.32156864, 0.6784314 ]],\n",
       "\n",
       "        [[0.9411765 , 0.9254902 , 0.94509804],\n",
       "         [0.92941177, 0.9372549 , 0.95686275],\n",
       "         [0.90588236, 0.8862745 , 0.93333334],\n",
       "         ...,\n",
       "         [0.47843137, 0.31764707, 0.8235294 ],\n",
       "         [0.5882353 , 0.4392157 , 0.8117647 ],\n",
       "         [0.627451  , 0.4627451 , 0.84705883]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.64705884, 0.49019608, 0.8666667 ],\n",
       "         [0.5372549 , 0.34117648, 0.67058825],\n",
       "         [0.5529412 , 0.3764706 , 0.7529412 ],\n",
       "         ...,\n",
       "         [0.59607846, 0.4392157 , 0.81960785],\n",
       "         [0.4862745 , 0.3137255 , 0.73333335],\n",
       "         [0.35686275, 0.19215687, 0.53333336]],\n",
       "\n",
       "        [[0.6313726 , 0.45882353, 0.85490197],\n",
       "         [0.627451  , 0.45882353, 0.8352941 ],\n",
       "         [0.5764706 , 0.40784314, 0.8352941 ],\n",
       "         ...,\n",
       "         [0.7372549 , 0.6       , 0.8666667 ],\n",
       "         [0.7254902 , 0.5921569 , 0.84313726],\n",
       "         [0.49019608, 0.31764707, 0.64705884]],\n",
       "\n",
       "        [[0.5803922 , 0.4       , 0.8509804 ],\n",
       "         [0.64705884, 0.48235294, 0.827451  ],\n",
       "         [0.68235296, 0.5058824 , 0.8117647 ],\n",
       "         ...,\n",
       "         [0.6313726 , 0.44705883, 0.7490196 ],\n",
       "         [0.61960787, 0.44313726, 0.75686276],\n",
       "         [0.7294118 , 0.58431375, 0.8509804 ]]],\n",
       "\n",
       "\n",
       "       [[[0.6392157 , 0.47058824, 0.70980394],\n",
       "         [0.6431373 , 0.47058824, 0.6627451 ],\n",
       "         [0.5568628 , 0.35686275, 0.6313726 ],\n",
       "         ...,\n",
       "         [0.6       , 0.3764706 , 0.5882353 ],\n",
       "         [0.6156863 , 0.39607844, 0.6156863 ],\n",
       "         [0.5764706 , 0.36862746, 0.5568628 ]],\n",
       "\n",
       "        [[0.6156863 , 0.4392157 , 0.8117647 ],\n",
       "         [0.627451  , 0.46666667, 0.74509805],\n",
       "         [0.6627451 , 0.49411765, 0.78039217],\n",
       "         ...,\n",
       "         [0.5921569 , 0.37254903, 0.58431375],\n",
       "         [0.6627451 , 0.4745098 , 0.69803923],\n",
       "         [0.5647059 , 0.3372549 , 0.54901963]],\n",
       "\n",
       "        [[0.5294118 , 0.34509805, 0.83137256],\n",
       "         [0.57254905, 0.38431373, 0.81960785],\n",
       "         [0.7176471 , 0.58431375, 0.83137256],\n",
       "         ...,\n",
       "         [0.5568628 , 0.3372549 , 0.52156866],\n",
       "         [0.6784314 , 0.5058824 , 0.7137255 ],\n",
       "         [0.5647059 , 0.34901962, 0.5254902 ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.7372549 , 0.5882353 , 0.76862746],\n",
       "         [0.47843137, 0.2509804 , 0.4627451 ],\n",
       "         [0.5882353 , 0.3647059 , 0.6       ],\n",
       "         ...,\n",
       "         [0.5803922 , 0.3764706 , 0.6862745 ],\n",
       "         [0.6       , 0.42745098, 0.7921569 ],\n",
       "         [0.6039216 , 0.4509804 , 0.8156863 ]],\n",
       "\n",
       "        [[0.6901961 , 0.49803922, 0.67058825],\n",
       "         [0.62352943, 0.43137255, 0.69803923],\n",
       "         [0.5019608 , 0.29411766, 0.5254902 ],\n",
       "         ...,\n",
       "         [0.5294118 , 0.33333334, 0.6784314 ],\n",
       "         [0.6       , 0.39607844, 0.7019608 ],\n",
       "         [0.6745098 , 0.49803922, 0.8       ]],\n",
       "\n",
       "        [[0.62352943, 0.4745098 , 0.6392157 ],\n",
       "         [0.7529412 , 0.5921569 , 0.80784315],\n",
       "         [0.6117647 , 0.41960785, 0.74509805],\n",
       "         ...,\n",
       "         [0.54901963, 0.35686275, 0.7529412 ],\n",
       "         [0.5921569 , 0.42352942, 0.7176471 ],\n",
       "         [0.7137255 , 0.5686275 , 0.8156863 ]]]], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-27T07:53:01.944921Z",
     "start_time": "2020-07-27T07:53:01.935976Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[0.68235296, 0.5764706 , 0.8627451 ],\n",
       "         [0.6901961 , 0.5568628 , 0.79607844],\n",
       "         [0.7254902 , 0.60784316, 0.80784315],\n",
       "         ...,\n",
       "         [0.49803922, 0.29411766, 0.43137255],\n",
       "         [0.6431373 , 0.48235294, 0.6784314 ],\n",
       "         [0.5647059 , 0.3882353 , 0.5529412 ]],\n",
       "\n",
       "        [[0.72156864, 0.59607846, 0.8392157 ],\n",
       "         [0.8       , 0.7254902 , 0.8745098 ],\n",
       "         [0.7058824 , 0.5764706 , 0.81960785],\n",
       "         ...,\n",
       "         [0.61960787, 0.4509804 , 0.6431373 ],\n",
       "         [0.6392157 , 0.47843137, 0.6039216 ],\n",
       "         [0.6039216 , 0.4117647 , 0.5803922 ]],\n",
       "\n",
       "        [[0.78431374, 0.6901961 , 0.79607844],\n",
       "         [0.79607844, 0.69803923, 0.80784315],\n",
       "         [0.7137255 , 0.5764706 , 0.8       ],\n",
       "         ...,\n",
       "         [0.6       , 0.43137255, 0.57254905],\n",
       "         [0.6862745 , 0.52156866, 0.6784314 ],\n",
       "         [0.5411765 , 0.34509805, 0.49411765]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.7490196 , 0.6392157 , 0.84313726],\n",
       "         [0.7294118 , 0.62352943, 0.7921569 ],\n",
       "         [0.7176471 , 0.5921569 , 0.7254902 ],\n",
       "         ...,\n",
       "         [0.75686276, 0.6156863 , 0.8117647 ],\n",
       "         [0.77254903, 0.6745098 , 0.83137256],\n",
       "         [0.78039217, 0.6666667 , 0.84313726]],\n",
       "\n",
       "        [[0.7019608 , 0.58431375, 0.83137256],\n",
       "         [0.56078434, 0.3882353 , 0.5686275 ],\n",
       "         [0.62352943, 0.47843137, 0.72156864],\n",
       "         ...,\n",
       "         [0.7294118 , 0.6156863 , 0.8039216 ],\n",
       "         [0.78039217, 0.65882355, 0.81960785],\n",
       "         [0.7647059 , 0.6627451 , 0.81960785]],\n",
       "\n",
       "        [[0.6627451 , 0.54509807, 0.75686276],\n",
       "         [0.7490196 , 0.6313726 , 0.8117647 ],\n",
       "         [0.6627451 , 0.5294118 , 0.7764706 ],\n",
       "         ...,\n",
       "         [0.74509805, 0.6156863 , 0.8039216 ],\n",
       "         [0.7490196 , 0.6509804 , 0.83137256],\n",
       "         [0.77254903, 0.6392157 , 0.827451  ]]],\n",
       "\n",
       "\n",
       "       [[[0.95686275, 0.9490196 , 0.95686275],\n",
       "         [0.95686275, 0.9490196 , 0.95686275],\n",
       "         [0.95686275, 0.9490196 , 0.9607843 ],\n",
       "         ...,\n",
       "         [0.56078434, 0.3529412 , 0.70980394],\n",
       "         [0.5803922 , 0.34117648, 0.7176471 ],\n",
       "         [0.5411765 , 0.30588236, 0.72156864]],\n",
       "\n",
       "        [[0.95686275, 0.9490196 , 0.95686275],\n",
       "         [0.95686275, 0.9490196 , 0.95686275],\n",
       "         [0.95686275, 0.9490196 , 0.9607843 ],\n",
       "         ...,\n",
       "         [0.50980395, 0.2784314 , 0.68235296],\n",
       "         [0.50980395, 0.3019608 , 0.70980394],\n",
       "         [0.5294118 , 0.3019608 , 0.69411767]],\n",
       "\n",
       "        [[0.95686275, 0.9529412 , 0.95686275],\n",
       "         [0.95686275, 0.9529412 , 0.9607843 ],\n",
       "         [0.95686275, 0.9529412 , 0.9607843 ],\n",
       "         ...,\n",
       "         [0.5137255 , 0.2627451 , 0.65882355],\n",
       "         [0.6392157 , 0.49411765, 0.77254903],\n",
       "         [0.5058824 , 0.25882354, 0.69411767]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.9607843 , 0.95686275, 0.9647059 ],\n",
       "         [0.9607843 , 0.95686275, 0.9647059 ],\n",
       "         [0.9607843 , 0.95686275, 0.9647059 ],\n",
       "         ...,\n",
       "         [0.95686275, 0.9529412 , 0.9607843 ],\n",
       "         [0.95686275, 0.9529412 , 0.9607843 ],\n",
       "         [0.95686275, 0.9529412 , 0.9607843 ]],\n",
       "\n",
       "        [[0.9607843 , 0.95686275, 0.9647059 ],\n",
       "         [0.9607843 , 0.95686275, 0.9647059 ],\n",
       "         [0.9647059 , 0.95686275, 0.9647059 ],\n",
       "         ...,\n",
       "         [0.95686275, 0.9529412 , 0.9607843 ],\n",
       "         [0.95686275, 0.9529412 , 0.9607843 ],\n",
       "         [0.95686275, 0.9529412 , 0.9607843 ]],\n",
       "\n",
       "        [[0.9607843 , 0.95686275, 0.9647059 ],\n",
       "         [0.9607843 , 0.95686275, 0.9647059 ],\n",
       "         [0.9647059 , 0.95686275, 0.9647059 ],\n",
       "         ...,\n",
       "         [0.95686275, 0.9529412 , 0.9607843 ],\n",
       "         [0.95686275, 0.9529412 , 0.9607843 ],\n",
       "         [0.95686275, 0.9529412 , 0.9607843 ]]],\n",
       "\n",
       "\n",
       "       [[[0.9490196 , 0.9411765 , 0.9529412 ],\n",
       "         [0.9490196 , 0.9411765 , 0.9529412 ],\n",
       "         [0.9490196 , 0.9411765 , 0.9529412 ],\n",
       "         ...,\n",
       "         [0.6431373 , 0.44705883, 0.69411767],\n",
       "         [0.60784316, 0.42352942, 0.7137255 ],\n",
       "         [0.654902  , 0.48235294, 0.7764706 ]],\n",
       "\n",
       "        [[0.9490196 , 0.9411765 , 0.9529412 ],\n",
       "         [0.9490196 , 0.9411765 , 0.9529412 ],\n",
       "         [0.9490196 , 0.9411765 , 0.9529412 ],\n",
       "         ...,\n",
       "         [0.4862745 , 0.27058825, 0.47058824],\n",
       "         [0.6       , 0.4117647 , 0.6117647 ],\n",
       "         [0.6901961 , 0.5019608 , 0.7529412 ]],\n",
       "\n",
       "        [[0.9490196 , 0.9411765 , 0.9529412 ],\n",
       "         [0.9490196 , 0.9411765 , 0.9529412 ],\n",
       "         [0.94509804, 0.9372549 , 0.9490196 ],\n",
       "         ...,\n",
       "         [0.5411765 , 0.29803923, 0.5764706 ],\n",
       "         [0.5411765 , 0.30980393, 0.56078434],\n",
       "         [0.5529412 , 0.3254902 , 0.5686275 ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.6117647 , 0.42352942, 0.654902  ],\n",
       "         [0.64705884, 0.45882353, 0.7647059 ],\n",
       "         [0.6666667 , 0.50980395, 0.6862745 ],\n",
       "         ...,\n",
       "         [0.68235296, 0.5529412 , 0.8       ],\n",
       "         [0.69803923, 0.56078434, 0.77254903],\n",
       "         [0.6156863 , 0.42745098, 0.7764706 ]],\n",
       "\n",
       "        [[0.61960787, 0.42352942, 0.75686276],\n",
       "         [0.59607846, 0.42745098, 0.76862746],\n",
       "         [0.6901961 , 0.5058824 , 0.7294118 ],\n",
       "         ...,\n",
       "         [0.5372549 , 0.34901962, 0.7411765 ],\n",
       "         [0.54901963, 0.35686275, 0.78431374],\n",
       "         [0.6       , 0.41960785, 0.78039217]],\n",
       "\n",
       "        [[0.6666667 , 0.5058824 , 0.73333335],\n",
       "         [0.59607846, 0.40784314, 0.7019608 ],\n",
       "         [0.6745098 , 0.48235294, 0.7529412 ],\n",
       "         ...,\n",
       "         [0.63529414, 0.4392157 , 0.7764706 ],\n",
       "         [0.6039216 , 0.42745098, 0.74509805],\n",
       "         [0.654902  , 0.47843137, 0.7294118 ]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[0.6313726 , 0.40784314, 0.69411767],\n",
       "         [0.6313726 , 0.4117647 , 0.63529414],\n",
       "         [0.627451  , 0.41960785, 0.57254905],\n",
       "         ...,\n",
       "         [0.6392157 , 0.44313726, 0.73333335],\n",
       "         [0.68235296, 0.46666667, 0.7411765 ],\n",
       "         [0.6509804 , 0.44313726, 0.70980394]],\n",
       "\n",
       "        [[0.6627451 , 0.43529412, 0.69803923],\n",
       "         [0.6431373 , 0.42745098, 0.64705884],\n",
       "         [0.6313726 , 0.41568628, 0.6509804 ],\n",
       "         ...,\n",
       "         [0.6745098 , 0.4862745 , 0.7411765 ],\n",
       "         [0.64705884, 0.43529412, 0.73333335],\n",
       "         [0.62352943, 0.3882353 , 0.65882355]],\n",
       "\n",
       "        [[0.6156863 , 0.36862746, 0.60784316],\n",
       "         [0.54509807, 0.2901961 , 0.46666667],\n",
       "         [0.47843137, 0.24705882, 0.40784314],\n",
       "         ...,\n",
       "         [0.5803922 , 0.34901962, 0.7019608 ],\n",
       "         [0.7058824 , 0.5019608 , 0.74509805],\n",
       "         [0.6745098 , 0.5137255 , 0.7254902 ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.5882353 , 0.3647059 , 0.7254902 ],\n",
       "         [0.5137255 , 0.2784314 , 0.6313726 ],\n",
       "         [0.49803922, 0.26666668, 0.5019608 ],\n",
       "         ...,\n",
       "         [0.5019608 , 0.2627451 , 0.39607844],\n",
       "         [0.6       , 0.38431373, 0.56078434],\n",
       "         [0.5803922 , 0.34117648, 0.5058824 ]],\n",
       "\n",
       "        [[0.64705884, 0.4509804 , 0.7490196 ],\n",
       "         [0.73333335, 0.59607846, 0.78039217],\n",
       "         [0.69411767, 0.49803922, 0.70980394],\n",
       "         ...,\n",
       "         [0.5882353 , 0.36862746, 0.5764706 ],\n",
       "         [0.56078434, 0.3019608 , 0.49803922],\n",
       "         [0.6117647 , 0.41960785, 0.62352943]],\n",
       "\n",
       "        [[0.5568628 , 0.3372549 , 0.6862745 ],\n",
       "         [0.7058824 , 0.5176471 , 0.7176471 ],\n",
       "         [0.5764706 , 0.3529412 , 0.5176471 ],\n",
       "         ...,\n",
       "         [0.52156866, 0.27450982, 0.41568628],\n",
       "         [0.45882353, 0.23529412, 0.36862746],\n",
       "         [0.5176471 , 0.27450982, 0.41960785]]],\n",
       "\n",
       "\n",
       "       [[[0.827451  , 0.7176471 , 0.8666667 ],\n",
       "         [0.8784314 , 0.827451  , 0.9254902 ],\n",
       "         [0.9411765 , 0.9372549 , 0.9490196 ],\n",
       "         ...,\n",
       "         [0.75686276, 0.64705884, 0.8039216 ],\n",
       "         [0.83137256, 0.7882353 , 0.8901961 ],\n",
       "         [0.87058824, 0.83137256, 0.91764706]],\n",
       "\n",
       "        [[0.92156863, 0.9098039 , 0.93333334],\n",
       "         [0.92941177, 0.8980392 , 0.9254902 ],\n",
       "         [0.93333334, 0.90588236, 0.9372549 ],\n",
       "         ...,\n",
       "         [0.654902  , 0.49411765, 0.76862746],\n",
       "         [0.9137255 , 0.8980392 , 0.92156863],\n",
       "         [0.93333334, 0.9254902 , 0.93333334]],\n",
       "\n",
       "        [[0.9372549 , 0.92156863, 0.9411765 ],\n",
       "         [0.9098039 , 0.8901961 , 0.92941177],\n",
       "         [0.84705883, 0.78431374, 0.88235295],\n",
       "         ...,\n",
       "         [0.89411765, 0.8392157 , 0.90588236],\n",
       "         [0.91764706, 0.92156863, 0.9411765 ],\n",
       "         [0.9372549 , 0.92941177, 0.9490196 ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.91764706, 0.9098039 , 0.9529412 ],\n",
       "         [0.87058824, 0.8156863 , 0.88235295],\n",
       "         [0.85882354, 0.78039217, 0.8784314 ],\n",
       "         ...,\n",
       "         [0.4745098 , 0.25882354, 0.49019608],\n",
       "         [0.54509807, 0.2901961 , 0.54901963],\n",
       "         [0.57254905, 0.34117648, 0.69411767]],\n",
       "\n",
       "        [[0.8901961 , 0.8392157 , 0.89411765],\n",
       "         [0.9490196 , 0.92156863, 0.95686275],\n",
       "         [0.89411765, 0.85882354, 0.89411765],\n",
       "         ...,\n",
       "         [0.4862745 , 0.27058825, 0.45490196],\n",
       "         [0.5019608 , 0.28235295, 0.5058824 ],\n",
       "         [0.5411765 , 0.3137255 , 0.62352943]],\n",
       "\n",
       "        [[0.89411765, 0.85490197, 0.9019608 ],\n",
       "         [0.93333334, 0.9411765 , 0.9490196 ],\n",
       "         [0.93333334, 0.9098039 , 0.9411765 ],\n",
       "         ...,\n",
       "         [0.43529412, 0.21176471, 0.4392157 ],\n",
       "         [0.5294118 , 0.34901962, 0.654902  ],\n",
       "         [0.57254905, 0.36862746, 0.60784316]]],\n",
       "\n",
       "\n",
       "       [[[0.92156863, 0.8980392 , 0.9372549 ],\n",
       "         [0.92941177, 0.9254902 , 0.94509804],\n",
       "         [0.9254902 , 0.91764706, 0.9411765 ],\n",
       "         ...,\n",
       "         [0.84313726, 0.78431374, 0.9137255 ],\n",
       "         [0.81960785, 0.76862746, 0.92941177],\n",
       "         [0.92156863, 0.91764706, 0.9411765 ]],\n",
       "\n",
       "        [[0.79607844, 0.7529412 , 0.92156863],\n",
       "         [0.90588236, 0.85490197, 0.9254902 ],\n",
       "         [0.92156863, 0.9098039 , 0.92941177],\n",
       "         ...,\n",
       "         [0.8352941 , 0.77254903, 0.90588236],\n",
       "         [0.78039217, 0.7176471 , 0.9098039 ],\n",
       "         [0.89411765, 0.87058824, 0.92941177]],\n",
       "\n",
       "        [[0.8392157 , 0.7882353 , 0.9098039 ],\n",
       "         [0.8       , 0.7137255 , 0.9098039 ],\n",
       "         [0.8235294 , 0.7647059 , 0.92156863],\n",
       "         ...,\n",
       "         [0.8352941 , 0.7882353 , 0.9019608 ],\n",
       "         [0.92156863, 0.92941177, 0.9411765 ],\n",
       "         [0.93333334, 0.8980392 , 0.9411765 ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.8509804 , 0.8156863 , 0.92156863],\n",
       "         [0.85490197, 0.81960785, 0.92156863],\n",
       "         [0.88235295, 0.84705883, 0.92156863],\n",
       "         ...,\n",
       "         [0.77254903, 0.68235296, 0.8901961 ],\n",
       "         [0.7764706 , 0.70980394, 0.89411765],\n",
       "         [0.7647059 , 0.7058824 , 0.9019608 ]],\n",
       "\n",
       "        [[0.8862745 , 0.84313726, 0.9254902 ],\n",
       "         [0.85882354, 0.81960785, 0.9254902 ],\n",
       "         [0.88235295, 0.8352941 , 0.9254902 ],\n",
       "         ...,\n",
       "         [0.7607843 , 0.7019608 , 0.9019608 ],\n",
       "         [0.8       , 0.7411765 , 0.92156863],\n",
       "         [0.85490197, 0.8117647 , 0.9254902 ]],\n",
       "\n",
       "        [[0.88235295, 0.8392157 , 0.92941177],\n",
       "         [0.8509804 , 0.80784315, 0.91764706],\n",
       "         [0.80784315, 0.75686276, 0.92941177],\n",
       "         ...,\n",
       "         [0.69803923, 0.6392157 , 0.8627451 ],\n",
       "         [0.6117647 , 0.49803922, 0.8039216 ],\n",
       "         [0.6039216 , 0.4745098 , 0.8392157 ]]]], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-27T07:53:03.645977Z",
     "start_time": "2020-07-27T07:53:03.632014Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " ...]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-27T07:53:07.770202Z",
     "start_time": "2020-07-27T07:53:07.756271Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " ...]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random undersampling to tackle data imbalance\n",
    "I will count the number of cases of benign (class 0) and malignant (class 1) cases to check for data imbalance which will affect the model to be more biased towards one particular class, overall affecting the accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-27T08:35:04.200930Z",
     "start_time": "2020-07-27T08:35:04.194971Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70901"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.count(0) #Checking the number of 0's in the array Y (this denotes number of malignant cases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-27T08:35:06.156310Z",
     "start_time": "2020-07-27T08:35:06.151331Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29099"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.count(1) #Checking the number of 1's in the array Y (this denotes number of malignant cases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-27T08:35:08.072171Z",
     "start_time": "2020-07-27T08:35:08.067213Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24778"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.count(1) #Checking the number of 1's in the array y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-27T08:35:09.988326Z",
     "start_time": "2020-07-27T08:35:09.983370Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60222"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.count(0) #Checking the number of 0's in the array y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above results it can be observed that the number of benign cases outnumber the malignant ones. This can be solved by randomly undersampling the majority class and to make the number of samples in both classes equal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-27T08:35:12.877807Z",
     "start_time": "2020-07-27T08:35:12.873811Z"
    }
   },
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before random undersampling I will one-hot-encode the y_train and y_test, this is done to provide the machine learning algorithm, the categorical variable in a form, that will help it do a better job in prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-27T08:35:19.605571Z",
     "start_time": "2020-07-27T08:35:19.594600Z"
    }
   },
   "outputs": [],
   "source": [
    "#One-Hot-Encode y_train and y_test\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-27T07:53:24.883342Z",
     "start_time": "2020-07-27T07:53:24.879327Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       ...,\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-27T07:53:25.895858Z",
     "start_time": "2020-07-27T07:53:25.890870Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       ...,\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reshaping X_train and X_test to use Random Under Sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-27T08:35:30.727674Z",
     "start_time": "2020-07-27T08:35:30.722687Z"
    }
   },
   "outputs": [],
   "source": [
    "X_trainShape = X_train.shape[1]*X_train.shape[2]*X_train.shape[3]\n",
    "X_testShape = X_test.shape[1]*X_test.shape[2]*X_test.shape[3]\n",
    "X_trainFlat = X_train.reshape(X_train.shape[0], X_trainShape)\n",
    "X_testFlat = X_test.reshape(X_test.shape[0], X_testShape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-27T07:53:30.251515Z",
     "start_time": "2020-07-27T07:53:30.246494Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7500\n",
      "7500\n",
      "[[0.69803923 0.5803922  0.7019608  ... 0.7254902  0.627451   0.8627451 ]\n",
      " [0.8392157  0.7882353  0.8901961  ... 0.9372549  0.92941177 0.93333334]\n",
      " [0.9490196  0.9372549  0.9529412  ... 0.78039217 0.63529414 0.827451  ]\n",
      " ...\n",
      " [0.78431374 0.6745098  0.8352941  ... 0.5921569  0.39215687 0.80784315]\n",
      " [0.7529412  0.6392157  0.85882354 ... 0.7294118  0.58431375 0.8509804 ]\n",
      " [0.6392157  0.47058824 0.70980394 ... 0.7137255  0.5686275  0.8156863 ]]\n",
      "[[0.68235296 0.5764706  0.8627451  ... 0.77254903 0.6392157  0.827451  ]\n",
      " [0.95686275 0.9490196  0.95686275 ... 0.95686275 0.9529412  0.9607843 ]\n",
      " [0.9490196  0.9411765  0.9529412  ... 0.654902   0.47843137 0.7294118 ]\n",
      " ...\n",
      " [0.6313726  0.40784314 0.69411767 ... 0.5176471  0.27450982 0.41960785]\n",
      " [0.827451   0.7176471  0.8666667  ... 0.57254905 0.36862746 0.60784316]\n",
      " [0.92156863 0.8980392  0.9372549  ... 0.6039216  0.4745098  0.8392157 ]]\n"
     ]
    }
   ],
   "source": [
    "print(X_trainShape)\n",
    "print(X_testShape)\n",
    "print(X_trainFlat)\n",
    "print(X_testFlat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Random Under Sampler\n",
    "I am using sampling_strategy ='majority' as this will under sample the majority class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-27T08:35:37.339514Z",
     "start_time": "2020-07-27T08:35:34.553704Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\IwinEnv\\lib\\site-packages\\sklearn\\utils\\deprecation.py:143: FutureWarning: The sklearn.neighbors.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.neighbors. Anything that cannot be imported from sklearn.neighbors is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "D:\\Anaconda\\envs\\IwinEnv\\lib\\site-packages\\sklearn\\utils\\deprecation.py:143: FutureWarning: The sklearn.ensemble.bagging module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.ensemble. Anything that cannot be imported from sklearn.ensemble is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "D:\\Anaconda\\envs\\IwinEnv\\lib\\site-packages\\sklearn\\utils\\deprecation.py:143: FutureWarning: The sklearn.ensemble.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.ensemble. Anything that cannot be imported from sklearn.ensemble is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "D:\\Anaconda\\envs\\IwinEnv\\lib\\site-packages\\sklearn\\utils\\deprecation.py:143: FutureWarning: The sklearn.ensemble.forest module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.ensemble. Anything that cannot be imported from sklearn.ensemble is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "D:\\Anaconda\\envs\\IwinEnv\\lib\\site-packages\\sklearn\\utils\\deprecation.py:143: FutureWarning: The sklearn.utils.testing module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.utils. Anything that cannot be imported from sklearn.utils is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "D:\\Anaconda\\envs\\IwinEnv\\lib\\site-packages\\sklearn\\utils\\deprecation.py:143: FutureWarning: The sklearn.metrics.classification module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.metrics. Anything that cannot be imported from sklearn.metrics is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "D:\\Anaconda\\envs\\IwinEnv\\lib\\site-packages\\sklearn\\utils\\deprecation.py:86: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "D:\\Anaconda\\envs\\IwinEnv\\lib\\site-packages\\sklearn\\utils\\validation.py:71: FutureWarning: Pass classes=[0 1] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  FutureWarning)\n",
      "D:\\Anaconda\\envs\\IwinEnv\\lib\\site-packages\\sklearn\\utils\\deprecation.py:86: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "D:\\Anaconda\\envs\\IwinEnv\\lib\\site-packages\\sklearn\\utils\\validation.py:71: FutureWarning: Pass classes=[0 1] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "random_under_sampler = RandomUnderSampler(sampling_strategy='majority')\n",
    "X_trainRus, Y_trainRus = random_under_sampler.fit_sample(X_trainFlat, y_train)\n",
    "X_testRus, Y_testRus = random_under_sampler.fit_sample(X_testFlat, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-27T07:53:42.475325Z",
     "start_time": "2020-07-27T07:53:42.470338Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.8392157  0.76862746 0.9254902  ... 0.81960785 0.76862746 0.91764706]\n",
      " [0.9411765  0.9411765  0.9490196  ... 0.85490197 0.8        0.8509804 ]\n",
      " [0.8745098  0.83137256 0.95686275 ... 0.9647059  0.96862745 0.98039216]\n",
      " ...\n",
      " [0.58431375 0.3764706  0.84705883 ... 0.9411765  0.9372549  0.9411765 ]\n",
      " [0.9254902  0.91764706 0.95686275 ... 0.5647059  0.38431373 0.58431375]\n",
      " [0.6862745  0.54509807 0.85490197 ... 0.68235296 0.52156866 0.73333335]]\n",
      "[[0]\n",
      " [0]\n",
      " [0]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "[[0.91764706 0.91764706 0.92156863 ... 0.84313726 0.8        0.8352941 ]\n",
      " [0.6313726  0.39215687 0.7882353  ... 0.78431374 0.6862745  0.8901961 ]\n",
      " [0.8235294  0.77254903 0.9137255  ... 0.9098039  0.8745098  0.9372549 ]\n",
      " ...\n",
      " [0.5294118  0.31764707 0.44705883 ... 0.62352943 0.40784314 0.5921569 ]\n",
      " [0.41568628 0.21960784 0.3882353  ... 0.78039217 0.65882355 0.7490196 ]\n",
      " [0.6313726  0.40784314 0.69411767 ... 0.5176471  0.27450982 0.41960785]]\n",
      "[[0]\n",
      " [0]\n",
      " [0]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n"
     ]
    }
   ],
   "source": [
    "print(X_trainRus)\n",
    "print(Y_trainRus)\n",
    "print(X_testRus)\n",
    "print(Y_testRus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-27T08:35:41.982433Z",
     "start_time": "2020-07-27T08:35:41.978412Z"
    }
   },
   "outputs": [],
   "source": [
    "# One-hot-encoding\n",
    "Y_trainRusHot = to_categorical(Y_trainRus, num_classes = 2)\n",
    "Y_testRusHot = to_categorical(Y_testRus, num_classes = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-27T07:53:49.014600Z",
     "start_time": "2020-07-27T07:53:49.010580Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " ...\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]]\n",
      "[[1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " ...\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "print(Y_trainRusHot)\n",
    "print(Y_testRusHot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking the number of samples in each class to make sure RandomUnderSampling worked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-27T08:35:46.027704Z",
     "start_time": "2020-07-27T08:35:46.021720Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1]), array([24778, 24778], dtype=int64))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(Y_trainRus, return_counts=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-27T08:35:48.959215Z",
     "start_time": "2020-07-27T08:35:48.926329Z"
    }
   },
   "outputs": [],
   "source": [
    "for i in range(len(X_trainRus)):\n",
    "    height, width, channels = 50,50,3\n",
    "    X_trainRusReshaped = X_trainRus.reshape(len(X_trainRus),\\\n",
    "                                            height,width,channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-27T07:53:56.871371Z",
     "start_time": "2020-07-27T07:53:56.862397Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[0.8392157 , 0.76862746, 0.9254902 ],\n",
       "         [0.8392157 , 0.7647059 , 0.8862745 ],\n",
       "         [0.84313726, 0.77254903, 0.88235295],\n",
       "         ...,\n",
       "         [0.7137255 , 0.5921569 , 0.8901961 ],\n",
       "         [0.72156864, 0.6       , 0.89411765],\n",
       "         [0.72156864, 0.58431375, 0.8784314 ]],\n",
       "\n",
       "        [[0.79607844, 0.67058825, 0.8862745 ],\n",
       "         [0.81960785, 0.7372549 , 0.8901961 ],\n",
       "         [0.7607843 , 0.6509804 , 0.8745098 ],\n",
       "         ...,\n",
       "         [0.6627451 , 0.49803922, 0.87058824],\n",
       "         [0.67058825, 0.47058824, 0.8627451 ],\n",
       "         [0.63529414, 0.47058824, 0.85882354]],\n",
       "\n",
       "        [[0.67058825, 0.5568628 , 0.6666667 ],\n",
       "         [0.9137255 , 0.8862745 , 0.9411765 ],\n",
       "         [0.94509804, 0.93333334, 0.9529412 ],\n",
       "         ...,\n",
       "         [0.69411767, 0.54901963, 0.8745098 ],\n",
       "         [0.7176471 , 0.5803922 , 0.84705883],\n",
       "         [0.6862745 , 0.5176471 , 0.8745098 ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.5058824 , 0.3019608 , 0.56078434],\n",
       "         [0.57254905, 0.4       , 0.6745098 ],\n",
       "         [0.59607846, 0.4117647 , 0.78431374],\n",
       "         ...,\n",
       "         [0.6039216 , 0.42745098, 0.83137256],\n",
       "         [0.5921569 , 0.42352942, 0.8627451 ],\n",
       "         [0.58431375, 0.39607844, 0.84313726]],\n",
       "\n",
       "        [[0.63529414, 0.44313726, 0.8509804 ],\n",
       "         [0.58431375, 0.4117647 , 0.8039216 ],\n",
       "         [0.5647059 , 0.39607844, 0.7411765 ],\n",
       "         ...,\n",
       "         [0.6039216 , 0.41960785, 0.87058824],\n",
       "         [0.5803922 , 0.3882353 , 0.8666667 ],\n",
       "         [0.6039216 , 0.42352942, 0.85490197]],\n",
       "\n",
       "        [[0.63529414, 0.45490196, 0.8901961 ],\n",
       "         [0.6313726 , 0.45490196, 0.85882354],\n",
       "         [0.7058824 , 0.56078434, 0.8980392 ],\n",
       "         ...,\n",
       "         [0.69803923, 0.52156866, 0.8392157 ],\n",
       "         [0.77254903, 0.6666667 , 0.8666667 ],\n",
       "         [0.81960785, 0.76862746, 0.91764706]]],\n",
       "\n",
       "\n",
       "       [[[0.9411765 , 0.9411765 , 0.9490196 ],\n",
       "         [0.9490196 , 0.9372549 , 0.9529412 ],\n",
       "         [0.9411765 , 0.9254902 , 0.9490196 ],\n",
       "         ...,\n",
       "         [0.94509804, 0.92156863, 0.93333334],\n",
       "         [0.9372549 , 0.92941177, 0.92941177],\n",
       "         [0.92156863, 0.90588236, 0.93333334]],\n",
       "\n",
       "        [[0.94509804, 0.9411765 , 0.9372549 ],\n",
       "         [0.9607843 , 0.9411765 , 0.9490196 ],\n",
       "         [0.9490196 , 0.94509804, 0.93333334],\n",
       "         ...,\n",
       "         [0.92156863, 0.93333334, 0.9372549 ],\n",
       "         [0.93333334, 0.92156863, 0.9411765 ],\n",
       "         [0.93333334, 0.92941177, 0.9411765 ]],\n",
       "\n",
       "        [[0.8784314 , 0.8039216 , 0.8784314 ],\n",
       "         [0.88235295, 0.83137256, 0.8862745 ],\n",
       "         [0.9137255 , 0.89411765, 0.9411765 ],\n",
       "         ...,\n",
       "         [0.84705883, 0.7607843 , 0.8352941 ],\n",
       "         [0.85490197, 0.7764706 , 0.8509804 ],\n",
       "         [0.827451  , 0.72156864, 0.79607844]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.9372549 , 0.9411765 , 0.9490196 ],\n",
       "         [0.9529412 , 0.9411765 , 0.9372549 ],\n",
       "         [0.95686275, 0.9411765 , 0.94509804],\n",
       "         ...,\n",
       "         [0.8039216 , 0.70980394, 0.7647059 ],\n",
       "         [0.60784316, 0.42745098, 0.57254905],\n",
       "         [0.8666667 , 0.8156863 , 0.8627451 ]],\n",
       "\n",
       "        [[0.9529412 , 0.9372549 , 0.94509804],\n",
       "         [0.9411765 , 0.94509804, 0.94509804],\n",
       "         [0.94509804, 0.9411765 , 0.94509804],\n",
       "         ...,\n",
       "         [0.8039216 , 0.7176471 , 0.80784315],\n",
       "         [0.6       , 0.4392157 , 0.60784316],\n",
       "         [0.61960787, 0.4       , 0.6117647 ]],\n",
       "\n",
       "        [[0.89411765, 0.84705883, 0.8980392 ],\n",
       "         [0.92156863, 0.9019608 , 0.9254902 ],\n",
       "         [0.9490196 , 0.9372549 , 0.9490196 ],\n",
       "         ...,\n",
       "         [0.9372549 , 0.92941177, 0.9372549 ],\n",
       "         [0.92941177, 0.90588236, 0.92156863],\n",
       "         [0.85490197, 0.8       , 0.8509804 ]]],\n",
       "\n",
       "\n",
       "       [[[0.8745098 , 0.83137256, 0.95686275],\n",
       "         [0.78431374, 0.7058824 , 0.9411765 ],\n",
       "         [0.70980394, 0.6313726 , 0.9372549 ],\n",
       "         ...,\n",
       "         [0.84705883, 0.8039216 , 0.9647059 ],\n",
       "         [0.8235294 , 0.76862746, 0.9647059 ],\n",
       "         [0.85882354, 0.80784315, 0.9607843 ]],\n",
       "\n",
       "        [[0.79607844, 0.7372549 , 0.9529412 ],\n",
       "         [0.76862746, 0.6901961 , 0.9372549 ],\n",
       "         [0.77254903, 0.7058824 , 0.9372549 ],\n",
       "         ...,\n",
       "         [0.84313726, 0.78431374, 0.9607843 ],\n",
       "         [0.84705883, 0.80784315, 0.9607843 ],\n",
       "         [0.8352941 , 0.78039217, 0.9607843 ]],\n",
       "\n",
       "        [[0.8039216 , 0.7294118 , 0.94509804],\n",
       "         [0.7882353 , 0.7176471 , 0.9372549 ],\n",
       "         [0.77254903, 0.7058824 , 0.94509804],\n",
       "         ...,\n",
       "         [0.8235294 , 0.7607843 , 0.9647059 ],\n",
       "         [0.8352941 , 0.78039217, 0.95686275],\n",
       "         [0.827451  , 0.7529412 , 0.95686275]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.80784315, 0.7490196 , 0.9490196 ],\n",
       "         [0.7607843 , 0.6901961 , 0.9490196 ],\n",
       "         [0.8352941 , 0.7607843 , 0.9529412 ],\n",
       "         ...,\n",
       "         [0.9647059 , 0.9647059 , 0.9882353 ],\n",
       "         [0.96862745, 0.9764706 , 0.9764706 ],\n",
       "         [0.972549  , 0.96862745, 0.9843137 ]],\n",
       "\n",
       "        [[0.84705883, 0.78431374, 0.95686275],\n",
       "         [0.827451  , 0.7647059 , 0.95686275],\n",
       "         [0.75686276, 0.6901961 , 0.9372549 ],\n",
       "         ...,\n",
       "         [0.96862745, 0.972549  , 0.972549  ],\n",
       "         [0.96862745, 0.9607843 , 0.98039216],\n",
       "         [0.9607843 , 0.9647059 , 0.9843137 ]],\n",
       "\n",
       "        [[0.8       , 0.7372549 , 0.9607843 ],\n",
       "         [0.85490197, 0.8       , 0.9764706 ],\n",
       "         [0.88235295, 0.85490197, 0.9607843 ],\n",
       "         ...,\n",
       "         [0.9098039 , 0.8666667 , 0.9607843 ],\n",
       "         [0.9764706 , 0.9764706 , 0.98039216],\n",
       "         [0.9647059 , 0.96862745, 0.98039216]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[0.58431375, 0.3764706 , 0.84705883],\n",
       "         [0.70980394, 0.5647059 , 0.7764706 ],\n",
       "         [0.68235296, 0.49803922, 0.80784315],\n",
       "         ...,\n",
       "         [0.827451  , 0.70980394, 0.80784315],\n",
       "         [0.87058824, 0.8235294 , 0.89411765],\n",
       "         [0.8745098 , 0.8039216 , 0.8745098 ]],\n",
       "\n",
       "        [[0.60784316, 0.43529412, 0.85490197],\n",
       "         [0.69411767, 0.5019608 , 0.77254903],\n",
       "         [0.69803923, 0.52156866, 0.7764706 ],\n",
       "         ...,\n",
       "         [0.7921569 , 0.68235296, 0.78039217],\n",
       "         [0.8352941 , 0.7411765 , 0.8235294 ],\n",
       "         [0.8627451 , 0.7921569 , 0.8784314 ]],\n",
       "\n",
       "        [[0.68235296, 0.50980395, 0.83137256],\n",
       "         [0.67058825, 0.49019608, 0.79607844],\n",
       "         [0.68235296, 0.50980395, 0.7764706 ],\n",
       "         ...,\n",
       "         [0.8117647 , 0.70980394, 0.8       ],\n",
       "         [0.8392157 , 0.75686276, 0.81960785],\n",
       "         [0.88235295, 0.8156863 , 0.8901961 ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.8235294 , 0.7019608 , 0.77254903],\n",
       "         [0.85882354, 0.78431374, 0.8392157 ],\n",
       "         [0.69411767, 0.5254902 , 0.65882355],\n",
       "         ...,\n",
       "         [0.9372549 , 0.9254902 , 0.94509804],\n",
       "         [0.95686275, 0.94509804, 0.9529412 ],\n",
       "         [0.9411765 , 0.93333334, 0.9411765 ]],\n",
       "\n",
       "        [[0.83137256, 0.74509805, 0.8235294 ],\n",
       "         [0.84705883, 0.7647059 , 0.84313726],\n",
       "         [0.7882353 , 0.6666667 , 0.7882353 ],\n",
       "         ...,\n",
       "         [0.9529412 , 0.94509804, 0.94509804],\n",
       "         [0.9372549 , 0.92941177, 0.93333334],\n",
       "         [0.9490196 , 0.9254902 , 0.95686275]],\n",
       "\n",
       "        [[0.8392157 , 0.7529412 , 0.8235294 ],\n",
       "         [0.88235295, 0.8235294 , 0.88235295],\n",
       "         [0.7764706 , 0.6627451 , 0.75686276],\n",
       "         ...,\n",
       "         [0.93333334, 0.92156863, 0.9411765 ],\n",
       "         [0.9529412 , 0.9372549 , 0.9490196 ],\n",
       "         [0.9411765 , 0.9372549 , 0.9411765 ]]],\n",
       "\n",
       "\n",
       "       [[[0.9254902 , 0.91764706, 0.95686275],\n",
       "         [0.9372549 , 0.92156863, 0.9647059 ],\n",
       "         [0.92941177, 0.95686275, 0.96862745],\n",
       "         ...,\n",
       "         [0.654902  , 0.5176471 , 0.9019608 ],\n",
       "         [0.65882355, 0.54509807, 0.9137255 ],\n",
       "         [0.6862745 , 0.5686275 , 0.91764706]],\n",
       "\n",
       "        [[0.9529412 , 0.9490196 , 0.972549  ],\n",
       "         [0.9529412 , 0.9529412 , 0.95686275],\n",
       "         [0.95686275, 0.9411765 , 0.9607843 ],\n",
       "         ...,\n",
       "         [0.7529412 , 0.65882355, 0.7882353 ],\n",
       "         [0.6117647 , 0.50980395, 0.65882355],\n",
       "         [0.627451  , 0.5176471 , 0.78431374]],\n",
       "\n",
       "        [[0.9372549 , 0.9490196 , 0.9607843 ],\n",
       "         [0.9490196 , 0.94509804, 0.96862745],\n",
       "         [0.9490196 , 0.95686275, 0.9764706 ],\n",
       "         ...,\n",
       "         [0.9529412 , 0.9490196 , 0.972549  ],\n",
       "         [0.9647059 , 0.94509804, 0.96862745],\n",
       "         [0.92941177, 0.91764706, 0.9607843 ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.84313726, 0.78431374, 0.92156863],\n",
       "         [0.7411765 , 0.63529414, 0.8352941 ],\n",
       "         [0.7294118 , 0.60784316, 0.85490197],\n",
       "         ...,\n",
       "         [0.6784314 , 0.5294118 , 0.7882353 ],\n",
       "         [0.5058824 , 0.3254902 , 0.54901963],\n",
       "         [0.57254905, 0.41960785, 0.6901961 ]],\n",
       "\n",
       "        [[0.85490197, 0.8039216 , 0.9137255 ],\n",
       "         [0.6392157 , 0.49019608, 0.7176471 ],\n",
       "         [0.6745098 , 0.54901963, 0.78431374],\n",
       "         ...,\n",
       "         [0.64705884, 0.49411765, 0.6745098 ],\n",
       "         [0.53333336, 0.34509805, 0.5764706 ],\n",
       "         [0.5372549 , 0.36078432, 0.5176471 ]],\n",
       "\n",
       "        [[0.7137255 , 0.6039216 , 0.85490197],\n",
       "         [0.7176471 , 0.59607846, 0.7921569 ],\n",
       "         [0.6431373 , 0.5137255 , 0.81960785],\n",
       "         ...,\n",
       "         [0.68235296, 0.5411765 , 0.78039217],\n",
       "         [0.5176471 , 0.34117648, 0.5411765 ],\n",
       "         [0.5647059 , 0.38431373, 0.58431375]]],\n",
       "\n",
       "\n",
       "       [[[0.6862745 , 0.54509807, 0.85490197],\n",
       "         [0.6784314 , 0.5294118 , 0.8627451 ],\n",
       "         [0.69411767, 0.54509807, 0.8627451 ],\n",
       "         ...,\n",
       "         [0.9098039 , 0.8784314 , 0.92156863],\n",
       "         [0.78431374, 0.7058824 , 0.87058824],\n",
       "         [0.6862745 , 0.5294118 , 0.8235294 ]],\n",
       "\n",
       "        [[0.7137255 , 0.5686275 , 0.85490197],\n",
       "         [0.7019608 , 0.54509807, 0.8666667 ],\n",
       "         [0.64705884, 0.4862745 , 0.8627451 ],\n",
       "         ...,\n",
       "         [0.91764706, 0.91764706, 0.9372549 ],\n",
       "         [0.91764706, 0.8862745 , 0.91764706],\n",
       "         [0.7372549 , 0.5921569 , 0.83137256]],\n",
       "\n",
       "        [[0.60784316, 0.4509804 , 0.84313726],\n",
       "         [0.65882355, 0.49019608, 0.8627451 ],\n",
       "         [0.6509804 , 0.47843137, 0.85882354],\n",
       "         ...,\n",
       "         [0.9137255 , 0.8627451 , 0.9019608 ],\n",
       "         [0.78039217, 0.67058825, 0.8666667 ],\n",
       "         [0.64705884, 0.49019608, 0.7882353 ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.73333335, 0.59607846, 0.74509805],\n",
       "         [0.65882355, 0.4862745 , 0.7764706 ],\n",
       "         [0.69411767, 0.5294118 , 0.76862746],\n",
       "         ...,\n",
       "         [0.6745098 , 0.5019608 , 0.69411767],\n",
       "         [0.7254902 , 0.57254905, 0.81960785],\n",
       "         [0.6666667 , 0.48235294, 0.8235294 ]],\n",
       "\n",
       "        [[0.69411767, 0.5568628 , 0.7137255 ],\n",
       "         [0.5647059 , 0.3372549 , 0.5568628 ],\n",
       "         [0.57254905, 0.37254903, 0.5372549 ],\n",
       "         ...,\n",
       "         [0.6784314 , 0.5058824 , 0.69411767],\n",
       "         [0.6431373 , 0.46666667, 0.83137256],\n",
       "         [0.654902  , 0.47843137, 0.80784315]],\n",
       "\n",
       "        [[0.56078434, 0.34901962, 0.654902  ],\n",
       "         [0.5254902 , 0.3019608 , 0.7019608 ],\n",
       "         [0.52156866, 0.34117648, 0.6392157 ],\n",
       "         ...,\n",
       "         [0.69803923, 0.5568628 , 0.78039217],\n",
       "         [0.6392157 , 0.45882353, 0.7647059 ],\n",
       "         [0.68235296, 0.52156866, 0.73333335]]]], dtype=float32)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_trainRusReshaped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-27T08:35:54.224527Z",
     "start_time": "2020-07-27T08:35:54.215565Z"
    }
   },
   "outputs": [],
   "source": [
    "for i in range(len(X_testRus)):\n",
    "    height, width, channels = 50,50,3\n",
    "    X_testRusReshaped = X_testRus.reshape(len(X_testRus),\\\n",
    "                                          height,width,channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-27T07:54:00.590401Z",
     "start_time": "2020-07-27T07:54:00.581422Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[0.91764706, 0.91764706, 0.92156863],\n",
       "         [0.9254902 , 0.9137255 , 0.9254902 ],\n",
       "         [0.92156863, 0.9019608 , 0.92941177],\n",
       "         ...,\n",
       "         [0.73333335, 0.5803922 , 0.78039217],\n",
       "         [0.8980392 , 0.85490197, 0.8980392 ],\n",
       "         [0.8352941 , 0.7647059 , 0.8509804 ]],\n",
       "\n",
       "        [[0.9254902 , 0.9137255 , 0.92941177],\n",
       "         [0.91764706, 0.9019608 , 0.92156863],\n",
       "         [0.9254902 , 0.92941177, 0.92156863],\n",
       "         ...,\n",
       "         [0.80784315, 0.75686276, 0.85490197],\n",
       "         [0.87058824, 0.8156863 , 0.88235295],\n",
       "         [0.8235294 , 0.76862746, 0.8666667 ]],\n",
       "\n",
       "        [[0.9137255 , 0.9137255 , 0.9254902 ],\n",
       "         [0.9254902 , 0.9137255 , 0.92941177],\n",
       "         [0.8862745 , 0.84313726, 0.87058824],\n",
       "         ...,\n",
       "         [0.6117647 , 0.4117647 , 0.7137255 ],\n",
       "         [0.64705884, 0.49411765, 0.7490196 ],\n",
       "         [0.7019608 , 0.5568628 , 0.7529412 ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.87058824, 0.827451  , 0.8862745 ],\n",
       "         [0.7058824 , 0.6039216 , 0.7490196 ],\n",
       "         [0.65882355, 0.54509807, 0.67058825],\n",
       "         ...,\n",
       "         [0.43137255, 0.21568628, 0.33333334],\n",
       "         [0.6862745 , 0.56078434, 0.67058825],\n",
       "         [0.8509804 , 0.7921569 , 0.8509804 ]],\n",
       "\n",
       "        [[0.85882354, 0.8392157 , 0.8745098 ],\n",
       "         [0.83137256, 0.73333335, 0.8509804 ],\n",
       "         [0.9098039 , 0.8980392 , 0.91764706],\n",
       "         ...,\n",
       "         [0.6745098 , 0.5647059 , 0.6509804 ],\n",
       "         [0.68235296, 0.56078434, 0.6745098 ],\n",
       "         [0.8509804 , 0.8       , 0.8392157 ]],\n",
       "\n",
       "        [[0.8784314 , 0.8235294 , 0.87058824],\n",
       "         [0.7764706 , 0.6666667 , 0.80784315],\n",
       "         [0.77254903, 0.6627451 , 0.76862746],\n",
       "         ...,\n",
       "         [0.9098039 , 0.91764706, 0.92941177],\n",
       "         [0.92941177, 0.90588236, 0.91764706],\n",
       "         [0.84313726, 0.8       , 0.8352941 ]]],\n",
       "\n",
       "\n",
       "       [[[0.6313726 , 0.39215687, 0.7882353 ],\n",
       "         [0.63529414, 0.4       , 0.78431374],\n",
       "         [0.6509804 , 0.4117647 , 0.7882353 ],\n",
       "         ...,\n",
       "         [0.8862745 , 0.8862745 , 0.8980392 ],\n",
       "         [0.93333334, 0.9372549 , 0.94509804],\n",
       "         [0.9529412 , 0.93333334, 0.95686275]],\n",
       "\n",
       "        [[0.6509804 , 0.4       , 0.79607844],\n",
       "         [0.6509804 , 0.42352942, 0.7882353 ],\n",
       "         [0.65882355, 0.42745098, 0.78039217],\n",
       "         ...,\n",
       "         [0.94509804, 0.92941177, 0.9490196 ],\n",
       "         [0.9529412 , 0.92941177, 0.9490196 ],\n",
       "         [0.9411765 , 0.93333334, 0.9490196 ]],\n",
       "\n",
       "        [[0.6117647 , 0.36862746, 0.78039217],\n",
       "         [0.67058825, 0.4392157 , 0.80784315],\n",
       "         [0.65882355, 0.4392157 , 0.7764706 ],\n",
       "         ...,\n",
       "         [0.94509804, 0.9372549 , 0.9490196 ],\n",
       "         [0.94509804, 0.92941177, 0.9529412 ],\n",
       "         [0.9411765 , 0.93333334, 0.9529412 ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.9490196 , 0.9411765 , 0.9529412 ],\n",
       "         [0.9490196 , 0.9411765 , 0.9529412 ],\n",
       "         [0.9490196 , 0.9411765 , 0.9529412 ],\n",
       "         ...,\n",
       "         [0.6039216 , 0.36078432, 0.7529412 ],\n",
       "         [0.6117647 , 0.40392157, 0.78039217],\n",
       "         [0.89411765, 0.8352941 , 0.92941177]],\n",
       "\n",
       "        [[0.9490196 , 0.9411765 , 0.9529412 ],\n",
       "         [0.9490196 , 0.9411765 , 0.9529412 ],\n",
       "         [0.9490196 , 0.9411765 , 0.9529412 ],\n",
       "         ...,\n",
       "         [0.5803922 , 0.33333334, 0.73333335],\n",
       "         [0.7411765 , 0.61960787, 0.8627451 ],\n",
       "         [0.7137255 , 0.57254905, 0.85490197]],\n",
       "\n",
       "        [[0.9490196 , 0.9411765 , 0.9529412 ],\n",
       "         [0.9490196 , 0.9411765 , 0.9529412 ],\n",
       "         [0.9490196 , 0.9411765 , 0.9529412 ],\n",
       "         ...,\n",
       "         [0.5568628 , 0.3019608 , 0.72156864],\n",
       "         [0.68235296, 0.5176471 , 0.8352941 ],\n",
       "         [0.78431374, 0.6862745 , 0.8901961 ]]],\n",
       "\n",
       "\n",
       "       [[[0.8235294 , 0.77254903, 0.9137255 ],\n",
       "         [0.87058824, 0.80784315, 0.90588236],\n",
       "         [0.85882354, 0.827451  , 0.90588236],\n",
       "         ...,\n",
       "         [0.93333334, 0.93333334, 0.9411765 ],\n",
       "         [0.9372549 , 0.9372549 , 0.95686275],\n",
       "         [0.9529412 , 0.9372549 , 0.9529412 ]],\n",
       "\n",
       "        [[0.9411765 , 0.90588236, 0.9372549 ],\n",
       "         [0.9137255 , 0.89411765, 0.9372549 ],\n",
       "         [0.8235294 , 0.7921569 , 0.8862745 ],\n",
       "         ...,\n",
       "         [0.94509804, 0.9372549 , 0.94509804],\n",
       "         [0.91764706, 0.8784314 , 0.92941177],\n",
       "         [0.78039217, 0.7019608 , 0.8901961 ]],\n",
       "\n",
       "        [[0.93333334, 0.9411765 , 0.9529412 ],\n",
       "         [0.9411765 , 0.92941177, 0.9372549 ],\n",
       "         [0.9490196 , 0.9254902 , 0.9490196 ],\n",
       "         ...,\n",
       "         [0.8117647 , 0.7411765 , 0.9019608 ],\n",
       "         [0.59607846, 0.4627451 , 0.8117647 ],\n",
       "         [0.43529412, 0.29803923, 0.7372549 ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.89411765, 0.85882354, 0.93333334],\n",
       "         [0.84313726, 0.78431374, 0.8862745 ],\n",
       "         [0.76862746, 0.6509804 , 0.8235294 ],\n",
       "         ...,\n",
       "         [0.76862746, 0.69411767, 0.8509804 ],\n",
       "         [0.9019608 , 0.8745098 , 0.92156863],\n",
       "         [0.9411765 , 0.9411765 , 0.96862745]],\n",
       "\n",
       "        [[0.7411765 , 0.6392157 , 0.8235294 ],\n",
       "         [0.8117647 , 0.7529412 , 0.85490197],\n",
       "         [0.9098039 , 0.89411765, 0.9254902 ],\n",
       "         ...,\n",
       "         [0.94509804, 0.92156863, 0.95686275],\n",
       "         [0.8901961 , 0.8509804 , 0.92941177],\n",
       "         [0.85490197, 0.80784315, 0.92156863]],\n",
       "\n",
       "        [[0.92941177, 0.94509804, 0.93333334],\n",
       "         [0.9372549 , 0.9411765 , 0.9411765 ],\n",
       "         [0.9529412 , 0.92941177, 0.9490196 ],\n",
       "         ...,\n",
       "         [0.9529412 , 0.9411765 , 0.9529412 ],\n",
       "         [0.9411765 , 0.9490196 , 0.9529412 ],\n",
       "         [0.9098039 , 0.8745098 , 0.9372549 ]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[0.5294118 , 0.31764707, 0.44705883],\n",
       "         [0.6039216 , 0.38039216, 0.5176471 ],\n",
       "         [0.627451  , 0.40392157, 0.62352943],\n",
       "         ...,\n",
       "         [0.6313726 , 0.39215687, 0.5921569 ],\n",
       "         [0.62352943, 0.42352942, 0.5921569 ],\n",
       "         [0.49019608, 0.2627451 , 0.43529412]],\n",
       "\n",
       "        [[0.5019608 , 0.27058825, 0.43137255],\n",
       "         [0.5019608 , 0.2784314 , 0.4392157 ],\n",
       "         [0.53333336, 0.2784314 , 0.4745098 ],\n",
       "         ...,\n",
       "         [0.6745098 , 0.49019608, 0.63529414],\n",
       "         [0.5921569 , 0.36862746, 0.5882353 ],\n",
       "         [0.54901963, 0.29803923, 0.5176471 ]],\n",
       "\n",
       "        [[0.6156863 , 0.36862746, 0.5882353 ],\n",
       "         [0.5176471 , 0.34509805, 0.47843137],\n",
       "         [0.5294118 , 0.33333334, 0.48235294],\n",
       "         ...,\n",
       "         [0.7019608 , 0.5176471 , 0.6901961 ],\n",
       "         [0.53333336, 0.3019608 , 0.5882353 ],\n",
       "         [0.5568628 , 0.34509805, 0.5882353 ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.70980394, 0.5254902 , 0.69803923],\n",
       "         [0.5764706 , 0.3529412 , 0.5686275 ],\n",
       "         [0.5411765 , 0.29411766, 0.46666667],\n",
       "         ...,\n",
       "         [0.7254902 , 0.5921569 , 0.69803923],\n",
       "         [0.53333336, 0.3137255 , 0.52156866],\n",
       "         [0.62352943, 0.42352942, 0.6156863 ]],\n",
       "\n",
       "        [[0.5176471 , 0.2509804 , 0.47843137],\n",
       "         [0.5137255 , 0.26666668, 0.47058824],\n",
       "         [0.52156866, 0.3137255 , 0.5137255 ],\n",
       "         ...,\n",
       "         [0.627451  , 0.42745098, 0.60784316],\n",
       "         [0.63529414, 0.44705883, 0.65882355],\n",
       "         [0.6156863 , 0.40392157, 0.61960787]],\n",
       "\n",
       "        [[0.5137255 , 0.29411766, 0.4745098 ],\n",
       "         [0.53333336, 0.32156864, 0.5019608 ],\n",
       "         [0.6745098 , 0.46666667, 0.69803923],\n",
       "         ...,\n",
       "         [0.56078434, 0.3529412 , 0.5686275 ],\n",
       "         [0.47058824, 0.24705882, 0.42745098],\n",
       "         [0.62352943, 0.40784314, 0.5921569 ]]],\n",
       "\n",
       "\n",
       "       [[[0.41568628, 0.21960784, 0.3882353 ],\n",
       "         [0.43137255, 0.22745098, 0.3647059 ],\n",
       "         [0.5686275 , 0.4       , 0.54901963],\n",
       "         ...,\n",
       "         [0.85490197, 0.80784315, 0.8784314 ],\n",
       "         [0.91764706, 0.8980392 , 0.91764706],\n",
       "         [0.8862745 , 0.8627451 , 0.91764706]],\n",
       "\n",
       "        [[0.47058824, 0.27058825, 0.4627451 ],\n",
       "         [0.4509804 , 0.23921569, 0.4       ],\n",
       "         [0.6156863 , 0.5019608 , 0.5921569 ],\n",
       "         ...,\n",
       "         [0.8156863 , 0.7254902 , 0.8       ],\n",
       "         [0.81960785, 0.73333335, 0.8       ],\n",
       "         [0.74509805, 0.64705884, 0.7294118 ]],\n",
       "\n",
       "        [[0.4       , 0.21568628, 0.4117647 ],\n",
       "         [0.5568628 , 0.3647059 , 0.4862745 ],\n",
       "         [0.6313726 , 0.44705883, 0.654902  ],\n",
       "         ...,\n",
       "         [0.8666667 , 0.83137256, 0.8862745 ],\n",
       "         [0.85882354, 0.8117647 , 0.8901961 ],\n",
       "         [0.827451  , 0.78431374, 0.8352941 ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.83137256, 0.8666667 , 0.92941177],\n",
       "         [0.9254902 , 0.92156863, 0.9372549 ],\n",
       "         [0.9372549 , 0.92156863, 0.94509804],\n",
       "         ...,\n",
       "         [0.40784314, 0.16862746, 0.39215687],\n",
       "         [0.3254902 , 0.11372549, 0.3019608 ],\n",
       "         [0.34509805, 0.16862746, 0.3372549 ]],\n",
       "\n",
       "        [[0.8862745 , 0.9019608 , 0.93333334],\n",
       "         [0.92156863, 0.9137255 , 0.94509804],\n",
       "         [0.9254902 , 0.92156863, 0.93333334],\n",
       "         ...,\n",
       "         [0.5647059 , 0.39607844, 0.62352943],\n",
       "         [0.79607844, 0.7294118 , 0.8352941 ],\n",
       "         [0.84705883, 0.7921569 , 0.8980392 ]],\n",
       "\n",
       "        [[0.9254902 , 0.9254902 , 0.93333334],\n",
       "         [0.92941177, 0.9254902 , 0.9411765 ],\n",
       "         [0.9019608 , 0.8862745 , 0.9411765 ],\n",
       "         ...,\n",
       "         [0.54901963, 0.30980393, 0.5568628 ],\n",
       "         [0.58431375, 0.44313726, 0.59607846],\n",
       "         [0.78039217, 0.65882355, 0.7490196 ]]],\n",
       "\n",
       "\n",
       "       [[[0.6313726 , 0.40784314, 0.69411767],\n",
       "         [0.6313726 , 0.4117647 , 0.63529414],\n",
       "         [0.627451  , 0.41960785, 0.57254905],\n",
       "         ...,\n",
       "         [0.6392157 , 0.44313726, 0.73333335],\n",
       "         [0.68235296, 0.46666667, 0.7411765 ],\n",
       "         [0.6509804 , 0.44313726, 0.70980394]],\n",
       "\n",
       "        [[0.6627451 , 0.43529412, 0.69803923],\n",
       "         [0.6431373 , 0.42745098, 0.64705884],\n",
       "         [0.6313726 , 0.41568628, 0.6509804 ],\n",
       "         ...,\n",
       "         [0.6745098 , 0.4862745 , 0.7411765 ],\n",
       "         [0.64705884, 0.43529412, 0.73333335],\n",
       "         [0.62352943, 0.3882353 , 0.65882355]],\n",
       "\n",
       "        [[0.6156863 , 0.36862746, 0.60784316],\n",
       "         [0.54509807, 0.2901961 , 0.46666667],\n",
       "         [0.47843137, 0.24705882, 0.40784314],\n",
       "         ...,\n",
       "         [0.5803922 , 0.34901962, 0.7019608 ],\n",
       "         [0.7058824 , 0.5019608 , 0.74509805],\n",
       "         [0.6745098 , 0.5137255 , 0.7254902 ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.5882353 , 0.3647059 , 0.7254902 ],\n",
       "         [0.5137255 , 0.2784314 , 0.6313726 ],\n",
       "         [0.49803922, 0.26666668, 0.5019608 ],\n",
       "         ...,\n",
       "         [0.5019608 , 0.2627451 , 0.39607844],\n",
       "         [0.6       , 0.38431373, 0.56078434],\n",
       "         [0.5803922 , 0.34117648, 0.5058824 ]],\n",
       "\n",
       "        [[0.64705884, 0.4509804 , 0.7490196 ],\n",
       "         [0.73333335, 0.59607846, 0.78039217],\n",
       "         [0.69411767, 0.49803922, 0.70980394],\n",
       "         ...,\n",
       "         [0.5882353 , 0.36862746, 0.5764706 ],\n",
       "         [0.56078434, 0.3019608 , 0.49803922],\n",
       "         [0.6117647 , 0.41960785, 0.62352943]],\n",
       "\n",
       "        [[0.5568628 , 0.3372549 , 0.6862745 ],\n",
       "         [0.7058824 , 0.5176471 , 0.7176471 ],\n",
       "         [0.5764706 , 0.3529412 , 0.5176471 ],\n",
       "         ...,\n",
       "         [0.52156866, 0.27450982, 0.41568628],\n",
       "         [0.45882353, 0.23529412, 0.36862746],\n",
       "         [0.5176471 , 0.27450982, 0.41960785]]]], dtype=float32)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_testRusReshaped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-27T08:35:56.508866Z",
     "start_time": "2020-07-27T08:35:56.504902Z"
    }
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-27T08:35:58.470680Z",
     "start_time": "2020-07-27T08:35:58.466728Z"
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "num_classes = 2\n",
    "epochs = 40"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN Architecture\n",
    "I am using a sequential model which allows to create the model layer-by-layer. This architecture consists of convolutional layers, max pooling layers, dropout layers and fully connected layers.\n",
    "\n",
    "The first layer is a convolutional layer with 32 filter each of size 3 x 3.\n",
    "Also the input shape in the first layer is 50 x 50 x 3.\n",
    "Rectified linear unit (ReLU) activation function is the most common choice for the activation function and has been demonstrated to the very effective. I am using the ReLU layer for all the layers except the final output layer.\n",
    "\n",
    "The second layer is a pooling layer, which is used to reduce the dimension. Max Pooling with a 2x2 window only considers the maximum value in the 2x2 window\n",
    "\n",
    "The third layer is a convolutional layer of 64 filters of the size 3x3 followed by another max pooling layer of 2x2 window.\n",
    "\n",
    "The next two layers are convolutional layers wit he same filter size but with an increasing number of filters, 128 and 256 respectively.\n",
    "\n",
    "A flatten layer will be added which flattens the 3-Dimension feature map output from the convolutional layer to 1-Dimensional feature vector. This will then be added to the fully connected layer.\n",
    "\n",
    "The next layer is a dropout layer with a dropout rate of 0.5, which means that the 50% of the neurons in the neural network will be turned off randomly. This would help to prevent overfitting by making all the neurons learn about the data and not rely on only some neurons. Randomly turning off the neurons during training means other neurons will have to do the learning of the turned off neurons. This helps in generalizing and preventing overfitting.\n",
    "These dropout layers are added after each fully connected layers before the output layer, this also reduced the training time for each epochs.\n",
    "\n",
    "The next layer is another dense layer with 128 neurons.\n",
    "\n",
    "The final layer is a dense layer with the number of neurons equal to number of classes. I am using a sigmoid activation function as it is a binary classification problem. If it was a multi-class classification, I would be using the softmax activation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-27T08:36:13.273778Z",
     "start_time": "2020-07-27T08:36:13.096155Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Anaconda\\envs\\IwinEnv\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3,3),\n",
    "                 activation='relu',\n",
    "                 input_shape=(50,50,3)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(64, (3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(Conv2D(256, (3, 3), activation='relu'))\n",
    "# converting the 3D feature maps to 1D feature vectors for the- \n",
    "# dense layer below\n",
    "model.add(Flatten()) \n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(num_classes, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compiling the model\n",
    "The model is compiled using the binary cross entropy loss function and using the adaptive moment estimation (Adam) optimizer.\n",
    "Adam is an extension of the stochastic gradient descent, to update the network weights iterative based on the training data. It combines the advantages of both adaptive gradient algorithm and the root mean square propagation, it adapts the parameter learning rates based on the average first mean and also the average of the second means of the gradients.\n",
    "I am using a learning rate of 0.00001. Too high a learning rate can result in high weight changes that might result in overshooting the local minima and causes the training or validation error to fluctuate between the consecutive epochs. Similarly, too low a learning rate can result in increased network training times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-27T08:36:16.742753Z",
     "start_time": "2020-07-27T08:36:16.685889Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\iwin\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=keras.losses.binary_crossentropy,\n",
    "              optimizer=keras.optimizers.Adam(lr=0.00001),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Augmentation\n",
    "Keras ImageDataGenerator generates real time images during training using data augmentation. The more data I have the better the deep learning will work. \n",
    "Data augmentation helps generalize the model by reducing the networks capacity to overfit the training data. Common data augmentation techniques are rotation, vertical and horizontal flipping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-27T08:36:19.260676Z",
     "start_time": "2020-07-27T08:36:19.256687Z"
    }
   },
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    featurewise_center=True,\n",
    "    featurewise_std_normalization=True,\n",
    "    rotation_range=180,\n",
    "    horizontal_flip=True,vertical_flip = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model\n",
    "I am using a regularization method called Early Stopping, which is used to avoid  overfitting by stopping the training process when the parameter set to observe, in this case validation loss, does not improve for a certain number of epochs.\n",
    "I am also using Model Checkpoint to save the model. The monitor parameter allows to set a metric I will be monitoring, validation loss. When the validation loss is minimum the best model is saved to be used later to make predictions and evaluate the model's performance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-27T08:36:21.592932Z",
     "start_time": "2020-07-27T08:36:21.588937Z"
    }
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "early_stopping_monitor = EarlyStopping(monitor='val_loss',\\\n",
    "                                       patience=3, mode='min')\n",
    "model_checkpoint = ModelCheckpoint('best_model.h5', monitor='val_loss', \\\n",
    "                                   mode='min', verbose=1, \\\n",
    "                                   save_best_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As I am using ImageDataGenerator on the fly, I  will use model.fit_generator to train the model. I have set the variable 'training', which would help to plot the training loss and validation. This will give the variance or the difference between training error and validation set error.\n",
    "FOr validation, X_testRusReshaped and Y_testRusHot are used which was obtained after under-sampling x_test and y_test set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-27T08:45:10.170698Z",
     "start_time": "2020-07-27T08:36:27.039321Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Anaconda\\envs\\IwinEnv\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Epoch 1/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\IwinEnv\\lib\\site-packages\\keras_preprocessing\\image\\image_data_generator.py:716: UserWarning: This ImageDataGenerator specifies `featurewise_center`, but it hasn't been fit on any training data. Fit it first by calling `.fit(numpy_data)`.\n",
      "  warnings.warn('This ImageDataGenerator specifies '\n",
      "D:\\Anaconda\\envs\\IwinEnv\\lib\\site-packages\\keras_preprocessing\\image\\image_data_generator.py:724: UserWarning: This ImageDataGenerator specifies `featurewise_std_normalization`, but it hasn't been fit on any training data. Fit it first by calling `.fit(numpy_data)`.\n",
      "  warnings.warn('This ImageDataGenerator specifies '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "194/193 [==============================] - 29s 150ms/step - loss: 0.6858 - accuracy: 0.5337 - val_loss: 0.6554 - val_accuracy: 0.6675\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.65539, saving model to best_model.h5\n",
      "Epoch 2/40\n",
      "194/193 [==============================] - 25s 131ms/step - loss: 0.5960 - accuracy: 0.7030 - val_loss: 0.5276 - val_accuracy: 0.7483\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.65539 to 0.52761, saving model to best_model.h5\n",
      "Epoch 3/40\n",
      "194/193 [==============================] - 26s 133ms/step - loss: 0.5331 - accuracy: 0.7518 - val_loss: 0.5144 - val_accuracy: 0.7600\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.52761 to 0.51437, saving model to best_model.h5\n",
      "Epoch 4/40\n",
      "194/193 [==============================] - 26s 134ms/step - loss: 0.5244 - accuracy: 0.7585 - val_loss: 0.5088 - val_accuracy: 0.7646\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.51437 to 0.50879, saving model to best_model.h5\n",
      "Epoch 5/40\n",
      "194/193 [==============================] - 26s 133ms/step - loss: 0.5175 - accuracy: 0.7615 - val_loss: 0.5055 - val_accuracy: 0.7663\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.50879 to 0.50549, saving model to best_model.h5\n",
      "Epoch 6/40\n",
      "194/193 [==============================] - 26s 133ms/step - loss: 0.5140 - accuracy: 0.7633 - val_loss: 0.5025 - val_accuracy: 0.7685\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.50549 to 0.50249, saving model to best_model.h5\n",
      "Epoch 7/40\n",
      "194/193 [==============================] - 26s 134ms/step - loss: 0.5121 - accuracy: 0.7660 - val_loss: 0.4993 - val_accuracy: 0.7702\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.50249 to 0.49932, saving model to best_model.h5\n",
      "Epoch 8/40\n",
      "194/193 [==============================] - 26s 133ms/step - loss: 0.5086 - accuracy: 0.7683 - val_loss: 0.4967 - val_accuracy: 0.7716\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.49932 to 0.49671, saving model to best_model.h5\n",
      "Epoch 9/40\n",
      "194/193 [==============================] - 26s 133ms/step - loss: 0.5038 - accuracy: 0.7699 - val_loss: 0.5011 - val_accuracy: 0.7673\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.49671\n",
      "Epoch 10/40\n",
      "194/193 [==============================] - 26s 134ms/step - loss: 0.5017 - accuracy: 0.7718 - val_loss: 0.4939 - val_accuracy: 0.7703\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.49671 to 0.49392, saving model to best_model.h5\n",
      "Epoch 11/40\n",
      "194/193 [==============================] - 26s 133ms/step - loss: 0.5004 - accuracy: 0.7720 - val_loss: 0.4890 - val_accuracy: 0.7785\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.49392 to 0.48896, saving model to best_model.h5\n",
      "Epoch 12/40\n",
      "194/193 [==============================] - 26s 133ms/step - loss: 0.4992 - accuracy: 0.7735 - val_loss: 0.4870 - val_accuracy: 0.7777\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.48896 to 0.48701, saving model to best_model.h5\n",
      "Epoch 13/40\n",
      "194/193 [==============================] - 26s 135ms/step - loss: 0.4964 - accuracy: 0.7729 - val_loss: 0.4863 - val_accuracy: 0.7783\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.48701 to 0.48634, saving model to best_model.h5\n",
      "Epoch 14/40\n",
      "194/193 [==============================] - 26s 133ms/step - loss: 0.4923 - accuracy: 0.7766 - val_loss: 0.5022 - val_accuracy: 0.7657\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.48634\n",
      "Epoch 15/40\n",
      "194/193 [==============================] - 26s 133ms/step - loss: 0.4895 - accuracy: 0.7796 - val_loss: 0.4904 - val_accuracy: 0.7751\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.48634\n",
      "Epoch 16/40\n",
      "194/193 [==============================] - 26s 134ms/step - loss: 0.4875 - accuracy: 0.7813 - val_loss: 0.4839 - val_accuracy: 0.7814\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.48634 to 0.48388, saving model to best_model.h5\n",
      "Epoch 17/40\n",
      "194/193 [==============================] - 26s 133ms/step - loss: 0.4840 - accuracy: 0.7827 - val_loss: 0.4741 - val_accuracy: 0.7879\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.48388 to 0.47411, saving model to best_model.h5\n",
      "Epoch 18/40\n",
      "194/193 [==============================] - 26s 134ms/step - loss: 0.4792 - accuracy: 0.7857 - val_loss: 0.4857 - val_accuracy: 0.7799\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.47411\n",
      "Epoch 19/40\n",
      "194/193 [==============================] - 26s 134ms/step - loss: 0.4759 - accuracy: 0.7875 - val_loss: 0.4846 - val_accuracy: 0.7797\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.47411\n",
      "Epoch 20/40\n",
      "194/193 [==============================] - 26s 134ms/step - loss: 0.4736 - accuracy: 0.7886 - val_loss: 0.5053 - val_accuracy: 0.7665\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.47411\n"
     ]
    }
   ],
   "source": [
    "training = model.fit_generator(datagen.flow(X_trainRusReshaped,Y_trainRusHot,batch_size=batch_size),\n",
    "                    steps_per_epoch=len(X_trainRusReshaped) / batch_size, epochs=epochs,validation_data=(X_testRusReshaped, Y_testRusHot), verbose=1, callbacks=[early_stopping_monitor, model_checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-27T08:46:09.331098Z",
     "start_time": "2020-07-27T08:46:08.867863Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(training.history['loss'])\n",
    "plt.plot(training.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-27T08:46:29.044054Z",
     "start_time": "2020-07-27T08:46:25.643240Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3347  974]\n",
      " [ 858 3463]]\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "from sklearn import metrics\n",
    "model = load_model('best_model.h5')\n",
    "\n",
    "y_pred_one_hot = model.predict(X_testRusReshaped)\n",
    "y_pred_labels = np.argmax(y_pred_one_hot, axis = 1)\n",
    "\n",
    "y_true_labels = np.argmax(Y_testRusHot,axis=1)\n",
    "\n",
    "confusion_matrix = metrics.confusion_matrix(y_true=y_true_labels, y_pred=y_pred_labels)\n",
    "print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In cases such as this, having a lower false negative is better than having a lower false positive. This is because identifying a malignant tumour as benign is more dangerous than identifying a benign tumour as malignant, since the former will result in the patient receiving a different treatment due to misdiagnosis, and the latter is likely to go through further tests anyway.\n",
    "We can see that our model performs well with an accuracy of 79% on the test set. The confusion matrix only is also favourable for us and we have a model with low variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:IwinEnv] *",
   "language": "python",
   "name": "conda-env-IwinEnv-py"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
